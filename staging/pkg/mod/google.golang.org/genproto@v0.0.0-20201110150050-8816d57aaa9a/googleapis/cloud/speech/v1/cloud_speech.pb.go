// Copyright 2019 Google LLC.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.25.0
// 	protoc        v3.13.0
// source: google/cloud/speech/v1/cloud_speech.proto

package speech

import (
	context "context"
	reflect "reflect"
	sync "sync"

	proto "github.com/golang/protobuf/proto"
	_ "google.golang.org/genproto/googleapis/api/annotations"
	longrunning "google.golang.org/genproto/googleapis/longrunning"
	status "google.golang.org/genproto/googleapis/rpc/status"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status1 "google.golang.org/grpc/status"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	_ "google.golang.org/protobuf/types/known/anypb"
	durationpb "google.golang.org/protobuf/types/known/durationpb"
	timestamppb "google.golang.org/protobuf/types/known/timestamppb"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// This is a compile-time assertion that a sufficiently up-to-date version
// of the legacy proto package is being used.
const _ = proto.ProtoPackageIsVersion4

// The encoding of the audio data sent in the request.
//
// All encodings support only 1 channel (mono) audio, unless the
// `audio_channel_count` and `enable_separate_recognition_per_channel` fields
// are set.
//
// For best results, the audio source should be captured and transmitted using
// a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
// recognition can be reduced if lossy codecs are used to capture or transmit
// audio, particularly if background noise is present. Lossy codecs include
// `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, `SPEEX_WITH_HEADER_BYTE`, and `MP3`.
//
// The `FLAC` and `WAV` audio file formats include a header that describes the
// included audio content. You can request recognition for `WAV` files that
// contain either `LINEAR16` or `MULAW` encoded audio.
// If you send `FLAC` or `WAV` audio file format in
// your request, you do not need to specify an `AudioEncoding`; the audio
// encoding format is determined from the file header. If you specify
// an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
// encoding configuration must match the encoding described in the audio
// header; otherwise the request returns an
// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT] error code.
type RecognitionConfig_AudioEncoding int32

const (
	// Not specified.
	RecognitionConfig_ENCODING_UNSPECIFIED RecognitionConfig_AudioEncoding = 0
	// Uncompressed 16-bit signed little-endian samples (Linear PCM).
	RecognitionConfig_LINEAR16 RecognitionConfig_AudioEncoding = 1
	// `FLAC` (Free Lossless Audio
	// Codec) is the recommended encoding because it is
	// lossless--therefore recognition is not compromised--and
	// requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
	// encoding supports 16-bit and 24-bit samples, however, not all fields in
	// `STREAMINFO` are supported.
	RecognitionConfig_FLAC RecognitionConfig_AudioEncoding = 2
	// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
	RecognitionConfig_MULAW RecognitionConfig_AudioEncoding = 3
	// Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
	RecognitionConfig_AMR RecognitionConfig_AudioEncoding = 4
	// Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
	RecognitionConfig_AMR_WB RecognitionConfig_AudioEncoding = 5
	// Opus encoded audio frames in Ogg container
	// ([OggOpus](https://wiki.xiph.org/OggOpus)).
	// `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
	RecognitionConfig_OGG_OPUS RecognitionConfig_AudioEncoding = 6
	// Although the use of lossy encodings is not recommended, if a very low
	// bitrate encoding is required, `OGG_OPUS` is highly preferred over
	// Speex encoding. The [Speex](https://speex.org/)  encoding supported by
	// Cloud Speech API has a header byte in each block, as in MIME type
	// `audio/x-speex-with-header-byte`.
	// It is a variant of the RTP Speex encoding defined in
	// [RFC 5574](https://tools.ietf.org/html/rfc5574).
	// The stream is a sequence of blocks, one block per RTP packet. Each block
	// starts with a byte containing the length of the block, in bytes, followed
	// by one or more frames of Speex data, padded to an integral number of
	// bytes (octets) as specified in RFC 5574. In other words, each RTP header
	// is replaced with a single byte containing the block length. Only Speex
	// wideband is supported. `sample_rate_hertz` must be 16000.
	RecognitionConfig_SPEEX_WITH_HEADER_BYTE RecognitionConfig_AudioEncoding = 7
)

// Enum value maps for RecognitionConfig_AudioEncoding.
var (
	RecognitionConfig_AudioEncoding_name = map[int32]string{
		0: "ENCODING_UNSPECIFIED",
		1: "LINEAR16",
		2: "FLAC",
		3: "MULAW",
		4: "AMR",
		5: "AMR_WB",
		6: "OGG_OPUS",
		7: "SPEEX_WITH_HEADER_BYTE",
	}
	RecognitionConfig_AudioEncoding_value = map[string]int32{
		"ENCODING_UNSPECIFIED":   0,
		"LINEAR16":               1,
		"FLAC":                   2,
		"MULAW":                  3,
		"AMR":                    4,
		"AMR_WB":                 5,
		"OGG_OPUS":               6,
		"SPEEX_WITH_HEADER_BYTE": 7,
	}
)

func (x RecognitionConfig_AudioEncoding) Enum() *RecognitionConfig_AudioEncoding {
	p := new(RecognitionConfig_AudioEncoding)
	*p = x
	return p
}

func (x RecognitionConfig_AudioEncoding) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (RecognitionConfig_AudioEncoding) Descriptor() protoreflect.EnumDescriptor {
	return file_google_cloud_speech_v1_cloud_speech_proto_enumTypes[0].Descriptor()
}

func (RecognitionConfig_AudioEncoding) Type() protoreflect.EnumType {
	return &file_google_cloud_speech_v1_cloud_speech_proto_enumTypes[0]
}

func (x RecognitionConfig_AudioEncoding) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use RecognitionConfig_AudioEncoding.Descriptor instead.
func (RecognitionConfig_AudioEncoding) EnumDescriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{4, 0}
}

// Use case categories that the audio recognition request can be described
// by.
type RecognitionMetadata_InteractionType int32

const (
	// Use case is either unknown or is something other than one of the other
	// values below.
	RecognitionMetadata_INTERACTION_TYPE_UNSPECIFIED RecognitionMetadata_InteractionType = 0
	// Multiple people in a conversation or discussion. For example in a
	// meeting with two or more people actively participating. Typically
	// all the primary people speaking would be in the same room (if not,
	// see PHONE_CALL)
	RecognitionMetadata_DISCUSSION RecognitionMetadata_InteractionType = 1
	// One or more persons lecturing or presenting to others, mostly
	// uninterrupted.
	RecognitionMetadata_PRESENTATION RecognitionMetadata_InteractionType = 2
	// A phone-call or video-conference in which two or more people, who are
	// not in the same room, are actively participating.
	RecognitionMetadata_PHONE_CALL RecognitionMetadata_InteractionType = 3
	// A recorded message intended for another person to listen to.
	RecognitionMetadata_VOICEMAIL RecognitionMetadata_InteractionType = 4
	// Professionally produced audio (eg. TV Show, Podcast).
	RecognitionMetadata_PROFESSIONALLY_PRODUCED RecognitionMetadata_InteractionType = 5
	// Transcribe spoken questions and queries into text.
	RecognitionMetadata_VOICE_SEARCH RecognitionMetadata_InteractionType = 6
	// Transcribe voice commands, such as for controlling a device.
	RecognitionMetadata_VOICE_COMMAND RecognitionMetadata_InteractionType = 7
	// Transcribe speech to text to create a written document, such as a
	// text-message, email or report.
	RecognitionMetadata_DICTATION RecognitionMetadata_InteractionType = 8
)

// Enum value maps for RecognitionMetadata_InteractionType.
var (
	RecognitionMetadata_InteractionType_name = map[int32]string{
		0: "INTERACTION_TYPE_UNSPECIFIED",
		1: "DISCUSSION",
		2: "PRESENTATION",
		3: "PHONE_CALL",
		4: "VOICEMAIL",
		5: "PROFESSIONALLY_PRODUCED",
		6: "VOICE_SEARCH",
		7: "VOICE_COMMAND",
		8: "DICTATION",
	}
	RecognitionMetadata_InteractionType_value = map[string]int32{
		"INTERACTION_TYPE_UNSPECIFIED": 0,
		"DISCUSSION":                   1,
		"PRESENTATION":                 2,
		"PHONE_CALL":                   3,
		"VOICEMAIL":                    4,
		"PROFESSIONALLY_PRODUCED":      5,
		"VOICE_SEARCH":                 6,
		"VOICE_COMMAND":                7,
		"DICTATION":                    8,
	}
)

func (x RecognitionMetadata_InteractionType) Enum() *RecognitionMetadata_InteractionType {
	p := new(RecognitionMetadata_InteractionType)
	*p = x
	return p
}

func (x RecognitionMetadata_InteractionType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (RecognitionMetadata_InteractionType) Descriptor() protoreflect.EnumDescriptor {
	return file_google_cloud_speech_v1_cloud_speech_proto_enumTypes[1].Descriptor()
}

func (RecognitionMetadata_InteractionType) Type() protoreflect.EnumType {
	return &file_google_cloud_speech_v1_cloud_speech_proto_enumTypes[1]
}

func (x RecognitionMetadata_InteractionType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use RecognitionMetadata_InteractionType.Descriptor instead.
func (RecognitionMetadata_InteractionType) EnumDescriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{6, 0}
}

// Enumerates the types of capture settings describing an audio file.
type RecognitionMetadata_MicrophoneDistance int32

const (
	// Audio type is not known.
	RecognitionMetadata_MICROPHONE_DISTANCE_UNSPECIFIED RecognitionMetadata_MicrophoneDistance = 0
	// The audio was captured from a closely placed microphone. Eg. phone,
	// dictaphone, or handheld microphone. Generally if there speaker is within
	// 1 meter of the microphone.
	RecognitionMetadata_NEARFIELD RecognitionMetadata_MicrophoneDistance = 1
	// The speaker if within 3 meters of the microphone.
	RecognitionMetadata_MIDFIELD RecognitionMetadata_MicrophoneDistance = 2
	// The speaker is more than 3 meters away from the microphone.
	RecognitionMetadata_FARFIELD RecognitionMetadata_MicrophoneDistance = 3
)

// Enum value maps for RecognitionMetadata_MicrophoneDistance.
var (
	RecognitionMetadata_MicrophoneDistance_name = map[int32]string{
		0: "MICROPHONE_DISTANCE_UNSPECIFIED",
		1: "NEARFIELD",
		2: "MIDFIELD",
		3: "FARFIELD",
	}
	RecognitionMetadata_MicrophoneDistance_value = map[string]int32{
		"MICROPHONE_DISTANCE_UNSPECIFIED": 0,
		"NEARFIELD":                       1,
		"MIDFIELD":                        2,
		"FARFIELD":                        3,
	}
)

func (x RecognitionMetadata_MicrophoneDistance) Enum() *RecognitionMetadata_MicrophoneDistance {
	p := new(RecognitionMetadata_MicrophoneDistance)
	*p = x
	return p
}

func (x RecognitionMetadata_MicrophoneDistance) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (RecognitionMetadata_MicrophoneDistance) Descriptor() protoreflect.EnumDescriptor {
	return file_google_cloud_speech_v1_cloud_speech_proto_enumTypes[2].Descriptor()
}

func (RecognitionMetadata_MicrophoneDistance) Type() protoreflect.EnumType {
	return &file_google_cloud_speech_v1_cloud_speech_proto_enumTypes[2]
}

func (x RecognitionMetadata_MicrophoneDistance) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use RecognitionMetadata_MicrophoneDistance.Descriptor instead.
func (RecognitionMetadata_MicrophoneDistance) EnumDescriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{6, 1}
}

// The original media the speech was recorded on.
type RecognitionMetadata_OriginalMediaType int32

const (
	// Unknown original media type.
	RecognitionMetadata_ORIGINAL_MEDIA_TYPE_UNSPECIFIED RecognitionMetadata_OriginalMediaType = 0
	// The speech data is an audio recording.
	RecognitionMetadata_AUDIO RecognitionMetadata_OriginalMediaType = 1
	// The speech data originally recorded on a video.
	RecognitionMetadata_VIDEO RecognitionMetadata_OriginalMediaType = 2
)

// Enum value maps for RecognitionMetadata_OriginalMediaType.
var (
	RecognitionMetadata_OriginalMediaType_name = map[int32]string{
		0: "ORIGINAL_MEDIA_TYPE_UNSPECIFIED",
		1: "AUDIO",
		2: "VIDEO",
	}
	RecognitionMetadata_OriginalMediaType_value = map[string]int32{
		"ORIGINAL_MEDIA_TYPE_UNSPECIFIED": 0,
		"AUDIO":                           1,
		"VIDEO":                           2,
	}
)

func (x RecognitionMetadata_OriginalMediaType) Enum() *RecognitionMetadata_OriginalMediaType {
	p := new(RecognitionMetadata_OriginalMediaType)
	*p = x
	return p
}

func (x RecognitionMetadata_OriginalMediaType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (RecognitionMetadata_OriginalMediaType) Descriptor() protoreflect.EnumDescriptor {
	return file_google_cloud_speech_v1_cloud_speech_proto_enumTypes[3].Descriptor()
}

func (RecognitionMetadata_OriginalMediaType) Type() protoreflect.EnumType {
	return &file_google_cloud_speech_v1_cloud_speech_proto_enumTypes[3]
}

func (x RecognitionMetadata_OriginalMediaType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use RecognitionMetadata_OriginalMediaType.Descriptor instead.
func (RecognitionMetadata_OriginalMediaType) EnumDescriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{6, 2}
}

// The type of device the speech was recorded with.
type RecognitionMetadata_RecordingDeviceType int32

const (
	// The recording device is unknown.
	RecognitionMetadata_RECORDING_DEVICE_TYPE_UNSPECIFIED RecognitionMetadata_RecordingDeviceType = 0
	// Speech was recorded on a smartphone.
	RecognitionMetadata_SMARTPHONE RecognitionMetadata_RecordingDeviceType = 1
	// Speech was recorded using a personal computer or tablet.
	RecognitionMetadata_PC RecognitionMetadata_RecordingDeviceType = 2
	// Speech was recorded over a phone line.
	RecognitionMetadata_PHONE_LINE RecognitionMetadata_RecordingDeviceType = 3
	// Speech was recorded in a vehicle.
	RecognitionMetadata_VEHICLE RecognitionMetadata_RecordingDeviceType = 4
	// Speech was recorded outdoors.
	RecognitionMetadata_OTHER_OUTDOOR_DEVICE RecognitionMetadata_RecordingDeviceType = 5
	// Speech was recorded indoors.
	RecognitionMetadata_OTHER_INDOOR_DEVICE RecognitionMetadata_RecordingDeviceType = 6
)

// Enum value maps for RecognitionMetadata_RecordingDeviceType.
var (
	RecognitionMetadata_RecordingDeviceType_name = map[int32]string{
		0: "RECORDING_DEVICE_TYPE_UNSPECIFIED",
		1: "SMARTPHONE",
		2: "PC",
		3: "PHONE_LINE",
		4: "VEHICLE",
		5: "OTHER_OUTDOOR_DEVICE",
		6: "OTHER_INDOOR_DEVICE",
	}
	RecognitionMetadata_RecordingDeviceType_value = map[string]int32{
		"RECORDING_DEVICE_TYPE_UNSPECIFIED": 0,
		"SMARTPHONE":                        1,
		"PC":                                2,
		"PHONE_LINE":                        3,
		"VEHICLE":                           4,
		"OTHER_OUTDOOR_DEVICE":              5,
		"OTHER_INDOOR_DEVICE":               6,
	}
)

func (x RecognitionMetadata_RecordingDeviceType) Enum() *RecognitionMetadata_RecordingDeviceType {
	p := new(RecognitionMetadata_RecordingDeviceType)
	*p = x
	return p
}

func (x RecognitionMetadata_RecordingDeviceType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (RecognitionMetadata_RecordingDeviceType) Descriptor() protoreflect.EnumDescriptor {
	return file_google_cloud_speech_v1_cloud_speech_proto_enumTypes[4].Descriptor()
}

func (RecognitionMetadata_RecordingDeviceType) Type() protoreflect.EnumType {
	return &file_google_cloud_speech_v1_cloud_speech_proto_enumTypes[4]
}

func (x RecognitionMetadata_RecordingDeviceType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use RecognitionMetadata_RecordingDeviceType.Descriptor instead.
func (RecognitionMetadata_RecordingDeviceType) EnumDescriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{6, 3}
}

// Indicates the type of speech event.
type StreamingRecognizeResponse_SpeechEventType int32

const (
	// No speech event specified.
	StreamingRecognizeResponse_SPEECH_EVENT_UNSPECIFIED StreamingRecognizeResponse_SpeechEventType = 0
	// This event indicates that the server has detected the end of the user's
	// speech utterance and expects no additional speech. Therefore, the server
	// will not process additional audio (although it may subsequently return
	// additional results). The client should stop sending additional audio
	// data, half-close the gRPC connection, and wait for any additional results
	// until the server closes the gRPC connection. This event is only sent if
	// `single_utterance` was set to `true`, and is not used otherwise.
	StreamingRecognizeResponse_END_OF_SINGLE_UTTERANCE StreamingRecognizeResponse_SpeechEventType = 1
)

// Enum value maps for StreamingRecognizeResponse_SpeechEventType.
var (
	StreamingRecognizeResponse_SpeechEventType_name = map[int32]string{
		0: "SPEECH_EVENT_UNSPECIFIED",
		1: "END_OF_SINGLE_UTTERANCE",
	}
	StreamingRecognizeResponse_SpeechEventType_value = map[string]int32{
		"SPEECH_EVENT_UNSPECIFIED": 0,
		"END_OF_SINGLE_UTTERANCE":  1,
	}
)

func (x StreamingRecognizeResponse_SpeechEventType) Enum() *StreamingRecognizeResponse_SpeechEventType {
	p := new(StreamingRecognizeResponse_SpeechEventType)
	*p = x
	return p
}

func (x StreamingRecognizeResponse_SpeechEventType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (StreamingRecognizeResponse_SpeechEventType) Descriptor() protoreflect.EnumDescriptor {
	return file_google_cloud_speech_v1_cloud_speech_proto_enumTypes[5].Descriptor()
}

func (StreamingRecognizeResponse_SpeechEventType) Type() protoreflect.EnumType {
	return &file_google_cloud_speech_v1_cloud_speech_proto_enumTypes[5]
}

func (x StreamingRecognizeResponse_SpeechEventType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use StreamingRecognizeResponse_SpeechEventType.Descriptor instead.
func (StreamingRecognizeResponse_SpeechEventType) EnumDescriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{12, 0}
}

// The top-level message sent by the client for the `Recognize` method.
type RecognizeRequest struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Required. Provides information to the recognizer that specifies how to
	// process the request.
	Config *RecognitionConfig `protobuf:"bytes,1,opt,name=config,proto3" json:"config,omitempty"`
	// Required. The audio data to be recognized.
	Audio *RecognitionAudio `protobuf:"bytes,2,opt,name=audio,proto3" json:"audio,omitempty"`
}

func (x *RecognizeRequest) Reset() {
	*x = RecognizeRequest{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[0]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *RecognizeRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognizeRequest) ProtoMessage() {}

func (x *RecognizeRequest) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[0]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognizeRequest.ProtoReflect.Descriptor instead.
func (*RecognizeRequest) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{0}
}

func (x *RecognizeRequest) GetConfig() *RecognitionConfig {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *RecognizeRequest) GetAudio() *RecognitionAudio {
	if x != nil {
		return x.Audio
	}
	return nil
}

// The top-level message sent by the client for the `LongRunningRecognize`
// method.
type LongRunningRecognizeRequest struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Required. Provides information to the recognizer that specifies how to
	// process the request.
	Config *RecognitionConfig `protobuf:"bytes,1,opt,name=config,proto3" json:"config,omitempty"`
	// Required. The audio data to be recognized.
	Audio *RecognitionAudio `protobuf:"bytes,2,opt,name=audio,proto3" json:"audio,omitempty"`
}

func (x *LongRunningRecognizeRequest) Reset() {
	*x = LongRunningRecognizeRequest{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[1]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *LongRunningRecognizeRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LongRunningRecognizeRequest) ProtoMessage() {}

func (x *LongRunningRecognizeRequest) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[1]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LongRunningRecognizeRequest.ProtoReflect.Descriptor instead.
func (*LongRunningRecognizeRequest) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{1}
}

func (x *LongRunningRecognizeRequest) GetConfig() *RecognitionConfig {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *LongRunningRecognizeRequest) GetAudio() *RecognitionAudio {
	if x != nil {
		return x.Audio
	}
	return nil
}

// The top-level message sent by the client for the `StreamingRecognize` method.
// Multiple `StreamingRecognizeRequest` messages are sent. The first message
// must contain a `streaming_config` message and must not contain
// `audio_content`. All subsequent messages must contain `audio_content` and
// must not contain a `streaming_config` message.
type StreamingRecognizeRequest struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// The streaming request, which is either a streaming config or audio content.
	//
	// Types that are assignable to StreamingRequest:
	//	*StreamingRecognizeRequest_StreamingConfig
	//	*StreamingRecognizeRequest_AudioContent
	StreamingRequest isStreamingRecognizeRequest_StreamingRequest `protobuf_oneof:"streaming_request"`
}

func (x *StreamingRecognizeRequest) Reset() {
	*x = StreamingRecognizeRequest{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[2]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *StreamingRecognizeRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamingRecognizeRequest) ProtoMessage() {}

func (x *StreamingRecognizeRequest) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[2]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamingRecognizeRequest.ProtoReflect.Descriptor instead.
func (*StreamingRecognizeRequest) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{2}
}

func (m *StreamingRecognizeRequest) GetStreamingRequest() isStreamingRecognizeRequest_StreamingRequest {
	if m != nil {
		return m.StreamingRequest
	}
	return nil
}

func (x *StreamingRecognizeRequest) GetStreamingConfig() *StreamingRecognitionConfig {
	if x, ok := x.GetStreamingRequest().(*StreamingRecognizeRequest_StreamingConfig); ok {
		return x.StreamingConfig
	}
	return nil
}

func (x *StreamingRecognizeRequest) GetAudioContent() []byte {
	if x, ok := x.GetStreamingRequest().(*StreamingRecognizeRequest_AudioContent); ok {
		return x.AudioContent
	}
	return nil
}

type isStreamingRecognizeRequest_StreamingRequest interface {
	isStreamingRecognizeRequest_StreamingRequest()
}

type StreamingRecognizeRequest_StreamingConfig struct {
	// Provides information to the recognizer that specifies how to process the
	// request. The first `StreamingRecognizeRequest` message must contain a
	// `streaming_config`  message.
	StreamingConfig *StreamingRecognitionConfig `protobuf:"bytes,1,opt,name=streaming_config,json=streamingConfig,proto3,oneof"`
}

type StreamingRecognizeRequest_AudioContent struct {
	// The audio data to be recognized. Sequential chunks of audio data are sent
	// in sequential `StreamingRecognizeRequest` messages. The first
	// `StreamingRecognizeRequest` message must not contain `audio_content` data
	// and all subsequent `StreamingRecognizeRequest` messages must contain
	// `audio_content` data. The audio bytes must be encoded as specified in
	// `RecognitionConfig`. Note: as with all bytes fields, proto buffers use a
	// pure binary representation (not base64). See
	// [content limits](https://cloud.google.com/speech-to-text/quotas#content).
	AudioContent []byte `protobuf:"bytes,2,opt,name=audio_content,json=audioContent,proto3,oneof"`
}

func (*StreamingRecognizeRequest_StreamingConfig) isStreamingRecognizeRequest_StreamingRequest() {}

func (*StreamingRecognizeRequest_AudioContent) isStreamingRecognizeRequest_StreamingRequest() {}

// Provides information to the recognizer that specifies how to process the
// request.
type StreamingRecognitionConfig struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Required. Provides information to the recognizer that specifies how to
	// process the request.
	Config *RecognitionConfig `protobuf:"bytes,1,opt,name=config,proto3" json:"config,omitempty"`
	// If `false` or omitted, the recognizer will perform continuous
	// recognition (continuing to wait for and process audio even if the user
	// pauses speaking) until the client closes the input stream (gRPC API) or
	// until the maximum time limit has been reached. May return multiple
	// `StreamingRecognitionResult`s with the `is_final` flag set to `true`.
	//
	// If `true`, the recognizer will detect a single spoken utterance. When it
	// detects that the user has paused or stopped speaking, it will return an
	// `END_OF_SINGLE_UTTERANCE` event and cease recognition. It will return no
	// more than one `StreamingRecognitionResult` with the `is_final` flag set to
	// `true`.
	SingleUtterance bool `protobuf:"varint,2,opt,name=single_utterance,json=singleUtterance,proto3" json:"single_utterance,omitempty"`
	// If `true`, interim results (tentative hypotheses) may be
	// returned as they become available (these interim results are indicated with
	// the `is_final=false` flag).
	// If `false` or omitted, only `is_final=true` result(s) are returned.
	InterimResults bool `protobuf:"varint,3,opt,name=interim_results,json=interimResults,proto3" json:"interim_results,omitempty"`
}

func (x *StreamingRecognitionConfig) Reset() {
	*x = StreamingRecognitionConfig{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[3]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *StreamingRecognitionConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamingRecognitionConfig) ProtoMessage() {}

func (x *StreamingRecognitionConfig) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[3]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamingRecognitionConfig.ProtoReflect.Descriptor instead.
func (*StreamingRecognitionConfig) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{3}
}

func (x *StreamingRecognitionConfig) GetConfig() *RecognitionConfig {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *StreamingRecognitionConfig) GetSingleUtterance() bool {
	if x != nil {
		return x.SingleUtterance
	}
	return false
}

func (x *StreamingRecognitionConfig) GetInterimResults() bool {
	if x != nil {
		return x.InterimResults
	}
	return false
}

// Provides information to the recognizer that specifies how to process the
// request.
type RecognitionConfig struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Encoding of audio data sent in all `RecognitionAudio` messages.
	// This field is optional for `FLAC` and `WAV` audio files and required
	// for all other audio formats. For details, see [AudioEncoding][google.cloud.speech.v1.RecognitionConfig.AudioEncoding].
	Encoding RecognitionConfig_AudioEncoding `protobuf:"varint,1,opt,name=encoding,proto3,enum=google.cloud.speech.v1.RecognitionConfig_AudioEncoding" json:"encoding,omitempty"`
	// Sample rate in Hertz of the audio data sent in all
	// `RecognitionAudio` messages. Valid values are: 8000-48000.
	// 16000 is optimal. For best results, set the sampling rate of the audio
	// source to 16000 Hz. If that's not possible, use the native sample rate of
	// the audio source (instead of re-sampling).
	// This field is optional for FLAC and WAV audio files, but is
	// required for all other audio formats. For details, see [AudioEncoding][google.cloud.speech.v1.RecognitionConfig.AudioEncoding].
	SampleRateHertz int32 `protobuf:"varint,2,opt,name=sample_rate_hertz,json=sampleRateHertz,proto3" json:"sample_rate_hertz,omitempty"`
	// The number of channels in the input audio data.
	// ONLY set this for MULTI-CHANNEL recognition.
	// Valid values for LINEAR16 and FLAC are `1`-`8`.
	// Valid values for OGG_OPUS are '1'-'254'.
	// Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`.
	// If `0` or omitted, defaults to one channel (mono).
	// Note: We only recognize the first channel by default.
	// To perform independent recognition on each channel set
	// `enable_separate_recognition_per_channel` to 'true'.
	AudioChannelCount int32 `protobuf:"varint,7,opt,name=audio_channel_count,json=audioChannelCount,proto3" json:"audio_channel_count,omitempty"`
	// This needs to be set to `true` explicitly and `audio_channel_count` > 1
	// to get each channel recognized separately. The recognition result will
	// contain a `channel_tag` field to state which channel that result belongs
	// to. If this is not true, we will only recognize the first channel. The
	// request is billed cumulatively for all channels recognized:
	// `audio_channel_count` multiplied by the length of the audio.
	EnableSeparateRecognitionPerChannel bool `protobuf:"varint,12,opt,name=enable_separate_recognition_per_channel,json=enableSeparateRecognitionPerChannel,proto3" json:"enable_separate_recognition_per_channel,omitempty"`
	// Required. The language of the supplied audio as a
	// [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
	// Example: "en-US".
	// See [Language
	// Support](https://cloud.google.com/speech-to-text/docs/languages) for a list
	// of the currently supported language codes.
	LanguageCode string `protobuf:"bytes,3,opt,name=language_code,json=languageCode,proto3" json:"language_code,omitempty"`
	// Maximum number of recognition hypotheses to be returned.
	// Specifically, the maximum number of `SpeechRecognitionAlternative` messages
	// within each `SpeechRecognitionResult`.
	// The server may return fewer than `max_alternatives`.
	// Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
	// one. If omitted, will return a maximum of one.
	MaxAlternatives int32 `protobuf:"varint,4,opt,name=max_alternatives,json=maxAlternatives,proto3" json:"max_alternatives,omitempty"`
	// If set to `true`, the server will attempt to filter out
	// profanities, replacing all but the initial character in each filtered word
	// with asterisks, e.g. "f***". If set to `false` or omitted, profanities
	// won't be filtered out.
	ProfanityFilter bool `protobuf:"varint,5,opt,name=profanity_filter,json=profanityFilter,proto3" json:"profanity_filter,omitempty"`
	// Array of [SpeechContext][google.cloud.speech.v1.SpeechContext].
	// A means to provide context to assist the speech recognition. For more
	// information, see
	// [speech
	// adaptation](https://cloud.google.com/speech-to-text/docs/context-strength).
	SpeechContexts []*SpeechContext `protobuf:"bytes,6,rep,name=speech_contexts,json=speechContexts,proto3" json:"speech_contexts,omitempty"`
	// If `true`, the top result includes a list of words and
	// the start and end time offsets (timestamps) for those words. If
	// `false`, no word-level time offset information is returned. The default is
	// `false`.
	EnableWordTimeOffsets bool `protobuf:"varint,8,opt,name=enable_word_time_offsets,json=enableWordTimeOffsets,proto3" json:"enable_word_time_offsets,omitempty"`
	// If 'true', adds punctuation to recognition result hypotheses.
	// This feature is only available in select languages. Setting this for
	// requests in other languages has no effect at all.
	// The default 'false' value does not add punctuation to result hypotheses.
	// Note: This is currently offered as an experimental service, complimentary
	// to all users. In the future this may be exclusively available as a
	// premium feature.
	EnableAutomaticPunctuation bool `protobuf:"varint,11,opt,name=enable_automatic_punctuation,json=enableAutomaticPunctuation,proto3" json:"enable_automatic_punctuation,omitempty"`
	// Config to enable speaker diarization and set additional
	// parameters to make diarization better suited for your application.
	// Note: When this is enabled, we send all the words from the beginning of the
	// audio for the top alternative in every consecutive STREAMING responses.
	// This is done in order to improve our speaker tags as our models learn to
	// identify the speakers in the conversation over time.
	// For non-streaming requests, the diarization results will be provided only
	// in the top alternative of the FINAL SpeechRecognitionResult.
	DiarizationConfig *SpeakerDiarizationConfig `protobuf:"bytes,19,opt,name=diarization_config,json=diarizationConfig,proto3" json:"diarization_config,omitempty"`
	// Metadata regarding this request.
	Metadata *RecognitionMetadata `protobuf:"bytes,9,opt,name=metadata,proto3" json:"metadata,omitempty"`
	// Which model to select for the given request. Select the model
	// best suited to your domain to get best results. If a model is not
	// explicitly specified, then we auto-select a model based on the parameters
	// in the RecognitionConfig.
	// <table>
	//   <tr>
	//     <td><b>Model</b></td>
	//     <td><b>Description</b></td>
	//   </tr>
	//   <tr>
	//     <td><code>command_and_search</code></td>
	//     <td>Best for short queries such as voice commands or voice search.</td>
	//   </tr>
	//   <tr>
	//     <td><code>phone_call</code></td>
	//     <td>Best for audio that originated from a phone call (typically
	//     recorded at an 8khz sampling rate).</td>
	//   </tr>
	//   <tr>
	//     <td><code>video</code></td>
	//     <td>Best for audio that originated from from video or includes multiple
	//         speakers. Ideally the audio is recorded at a 16khz or greater
	//         sampling rate. This is a premium model that costs more than the
	//         standard rate.</td>
	//   </tr>
	//   <tr>
	//     <td><code>default</code></td>
	//     <td>Best for audio that is not one of the specific audio models.
	//         For example, long-form audio. Ideally the audio is high-fidelity,
	//         recorded at a 16khz or greater sampling rate.</td>
	//   </tr>
	// </table>
	Model string `protobuf:"bytes,13,opt,name=model,proto3" json:"model,omitempty"`
	// Set to true to use an enhanced model for speech recognition.
	// If `use_enhanced` is set to true and the `model` field is not set, then
	// an appropriate enhanced model is chosen if an enhanced model exists for
	// the audio.
	//
	// If `use_enhanced` is true and an enhanced version of the specified model
	// does not exist, then the speech is recognized using the standard version
	// of the specified model.
	UseEnhanced bool `protobuf:"varint,14,opt,name=use_enhanced,json=useEnhanced,proto3" json:"use_enhanced,omitempty"`
}

func (x *RecognitionConfig) Reset() {
	*x = RecognitionConfig{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[4]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *RecognitionConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionConfig) ProtoMessage() {}

func (x *RecognitionConfig) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[4]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionConfig.ProtoReflect.Descriptor instead.
func (*RecognitionConfig) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{4}
}

func (x *RecognitionConfig) GetEncoding() RecognitionConfig_AudioEncoding {
	if x != nil {
		return x.Encoding
	}
	return RecognitionConfig_ENCODING_UNSPECIFIED
}

func (x *RecognitionConfig) GetSampleRateHertz() int32 {
	if x != nil {
		return x.SampleRateHertz
	}
	return 0
}

func (x *RecognitionConfig) GetAudioChannelCount() int32 {
	if x != nil {
		return x.AudioChannelCount
	}
	return 0
}

func (x *RecognitionConfig) GetEnableSeparateRecognitionPerChannel() bool {
	if x != nil {
		return x.EnableSeparateRecognitionPerChannel
	}
	return false
}

func (x *RecognitionConfig) GetLanguageCode() string {
	if x != nil {
		return x.LanguageCode
	}
	return ""
}

func (x *RecognitionConfig) GetMaxAlternatives() int32 {
	if x != nil {
		return x.MaxAlternatives
	}
	return 0
}

func (x *RecognitionConfig) GetProfanityFilter() bool {
	if x != nil {
		return x.ProfanityFilter
	}
	return false
}

func (x *RecognitionConfig) GetSpeechContexts() []*SpeechContext {
	if x != nil {
		return x.SpeechContexts
	}
	return nil
}

func (x *RecognitionConfig) GetEnableWordTimeOffsets() bool {
	if x != nil {
		return x.EnableWordTimeOffsets
	}
	return false
}

func (x *RecognitionConfig) GetEnableAutomaticPunctuation() bool {
	if x != nil {
		return x.EnableAutomaticPunctuation
	}
	return false
}

func (x *RecognitionConfig) GetDiarizationConfig() *SpeakerDiarizationConfig {
	if x != nil {
		return x.DiarizationConfig
	}
	return nil
}

func (x *RecognitionConfig) GetMetadata() *RecognitionMetadata {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *RecognitionConfig) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *RecognitionConfig) GetUseEnhanced() bool {
	if x != nil {
		return x.UseEnhanced
	}
	return false
}

// Config to enable speaker diarization.
type SpeakerDiarizationConfig struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// If 'true', enables speaker detection for each recognized word in
	// the top alternative of the recognition result using a speaker_tag provided
	// in the WordInfo.
	EnableSpeakerDiarization bool `protobuf:"varint,1,opt,name=enable_speaker_diarization,json=enableSpeakerDiarization,proto3" json:"enable_speaker_diarization,omitempty"`
	// Minimum number of speakers in the conversation. This range gives you more
	// flexibility by allowing the system to automatically determine the correct
	// number of speakers. If not set, the default value is 2.
	MinSpeakerCount int32 `protobuf:"varint,2,opt,name=min_speaker_count,json=minSpeakerCount,proto3" json:"min_speaker_count,omitempty"`
	// Maximum number of speakers in the conversation. This range gives you more
	// flexibility by allowing the system to automatically determine the correct
	// number of speakers. If not set, the default value is 6.
	MaxSpeakerCount int32 `protobuf:"varint,3,opt,name=max_speaker_count,json=maxSpeakerCount,proto3" json:"max_speaker_count,omitempty"`
	// Unused.
	//
	// Deprecated: Do not use.
	SpeakerTag int32 `protobuf:"varint,5,opt,name=speaker_tag,json=speakerTag,proto3" json:"speaker_tag,omitempty"`
}

func (x *SpeakerDiarizationConfig) Reset() {
	*x = SpeakerDiarizationConfig{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[5]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *SpeakerDiarizationConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeakerDiarizationConfig) ProtoMessage() {}

func (x *SpeakerDiarizationConfig) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[5]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SpeakerDiarizationConfig.ProtoReflect.Descriptor instead.
func (*SpeakerDiarizationConfig) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{5}
}

func (x *SpeakerDiarizationConfig) GetEnableSpeakerDiarization() bool {
	if x != nil {
		return x.EnableSpeakerDiarization
	}
	return false
}

func (x *SpeakerDiarizationConfig) GetMinSpeakerCount() int32 {
	if x != nil {
		return x.MinSpeakerCount
	}
	return 0
}

func (x *SpeakerDiarizationConfig) GetMaxSpeakerCount() int32 {
	if x != nil {
		return x.MaxSpeakerCount
	}
	return 0
}

// Deprecated: Do not use.
func (x *SpeakerDiarizationConfig) GetSpeakerTag() int32 {
	if x != nil {
		return x.SpeakerTag
	}
	return 0
}

// Description of audio data to be recognized.
type RecognitionMetadata struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// The use case most closely describing the audio content to be recognized.
	InteractionType RecognitionMetadata_InteractionType `protobuf:"varint,1,opt,name=interaction_type,json=interactionType,proto3,enum=google.cloud.speech.v1.RecognitionMetadata_InteractionType" json:"interaction_type,omitempty"`
	// The industry vertical to which this speech recognition request most
	// closely applies. This is most indicative of the topics contained
	// in the audio.  Use the 6-digit NAICS code to identify the industry
	// vertical - see https://www.naics.com/search/.
	IndustryNaicsCodeOfAudio uint32 `protobuf:"varint,3,opt,name=industry_naics_code_of_audio,json=industryNaicsCodeOfAudio,proto3" json:"industry_naics_code_of_audio,omitempty"`
	// The audio type that most closely describes the audio being recognized.
	MicrophoneDistance RecognitionMetadata_MicrophoneDistance `protobuf:"varint,4,opt,name=microphone_distance,json=microphoneDistance,proto3,enum=google.cloud.speech.v1.RecognitionMetadata_MicrophoneDistance" json:"microphone_distance,omitempty"`
	// The original media the speech was recorded on.
	OriginalMediaType RecognitionMetadata_OriginalMediaType `protobuf:"varint,5,opt,name=original_media_type,json=originalMediaType,proto3,enum=google.cloud.speech.v1.RecognitionMetadata_OriginalMediaType" json:"original_media_type,omitempty"`
	// The type of device the speech was recorded with.
	RecordingDeviceType RecognitionMetadata_RecordingDeviceType `protobuf:"varint,6,opt,name=recording_device_type,json=recordingDeviceType,proto3,enum=google.cloud.speech.v1.RecognitionMetadata_RecordingDeviceType" json:"recording_device_type,omitempty"`
	// The device used to make the recording.  Examples 'Nexus 5X' or
	// 'Polycom SoundStation IP 6000' or 'POTS' or 'VoIP' or
	// 'Cardioid Microphone'.
	RecordingDeviceName string `protobuf:"bytes,7,opt,name=recording_device_name,json=recordingDeviceName,proto3" json:"recording_device_name,omitempty"`
	// Mime type of the original audio file.  For example `audio/m4a`,
	// `audio/x-alaw-basic`, `audio/mp3`, `audio/3gpp`.
	// A list of possible audio mime types is maintained at
	// http://www.iana.org/assignments/media-types/media-types.xhtml#audio
	OriginalMimeType string `protobuf:"bytes,8,opt,name=original_mime_type,json=originalMimeType,proto3" json:"original_mime_type,omitempty"`
	// Description of the content. Eg. "Recordings of federal supreme court
	// hearings from 2012".
	AudioTopic string `protobuf:"bytes,10,opt,name=audio_topic,json=audioTopic,proto3" json:"audio_topic,omitempty"`
}

func (x *RecognitionMetadata) Reset() {
	*x = RecognitionMetadata{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[6]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *RecognitionMetadata) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionMetadata) ProtoMessage() {}

func (x *RecognitionMetadata) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[6]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionMetadata.ProtoReflect.Descriptor instead.
func (*RecognitionMetadata) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{6}
}

func (x *RecognitionMetadata) GetInteractionType() RecognitionMetadata_InteractionType {
	if x != nil {
		return x.InteractionType
	}
	return RecognitionMetadata_INTERACTION_TYPE_UNSPECIFIED
}

func (x *RecognitionMetadata) GetIndustryNaicsCodeOfAudio() uint32 {
	if x != nil {
		return x.IndustryNaicsCodeOfAudio
	}
	return 0
}

func (x *RecognitionMetadata) GetMicrophoneDistance() RecognitionMetadata_MicrophoneDistance {
	if x != nil {
		return x.MicrophoneDistance
	}
	return RecognitionMetadata_MICROPHONE_DISTANCE_UNSPECIFIED
}

func (x *RecognitionMetadata) GetOriginalMediaType() RecognitionMetadata_OriginalMediaType {
	if x != nil {
		return x.OriginalMediaType
	}
	return RecognitionMetadata_ORIGINAL_MEDIA_TYPE_UNSPECIFIED
}

func (x *RecognitionMetadata) GetRecordingDeviceType() RecognitionMetadata_RecordingDeviceType {
	if x != nil {
		return x.RecordingDeviceType
	}
	return RecognitionMetadata_RECORDING_DEVICE_TYPE_UNSPECIFIED
}

func (x *RecognitionMetadata) GetRecordingDeviceName() string {
	if x != nil {
		return x.RecordingDeviceName
	}
	return ""
}

func (x *RecognitionMetadata) GetOriginalMimeType() string {
	if x != nil {
		return x.OriginalMimeType
	}
	return ""
}

func (x *RecognitionMetadata) GetAudioTopic() string {
	if x != nil {
		return x.AudioTopic
	}
	return ""
}

// Provides "hints" to the speech recognizer to favor specific words and phrases
// in the results.
type SpeechContext struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// A list of strings containing words and phrases "hints" so that
	// the speech recognition is more likely to recognize them. This can be used
	// to improve the accuracy for specific words and phrases, for example, if
	// specific commands are typically spoken by the user. This can also be used
	// to add additional words to the vocabulary of the recognizer. See
	// [usage limits](https://cloud.google.com/speech-to-text/quotas#content).
	//
	// List items can also be set to classes for groups of words that represent
	// common concepts that occur in natural language. For example, rather than
	// providing phrase hints for every month of the year, using the $MONTH class
	// improves the likelihood of correctly transcribing audio that includes
	// months.
	Phrases []string `protobuf:"bytes,1,rep,name=phrases,proto3" json:"phrases,omitempty"`
}

func (x *SpeechContext) Reset() {
	*x = SpeechContext{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[7]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *SpeechContext) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechContext) ProtoMessage() {}

func (x *SpeechContext) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[7]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SpeechContext.ProtoReflect.Descriptor instead.
func (*SpeechContext) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{7}
}

func (x *SpeechContext) GetPhrases() []string {
	if x != nil {
		return x.Phrases
	}
	return nil
}

// Contains audio data in the encoding specified in the `RecognitionConfig`.
// Either `content` or `uri` must be supplied. Supplying both or neither
// returns [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. See
// [content limits](https://cloud.google.com/speech-to-text/quotas#content).
type RecognitionAudio struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// The audio source, which is either inline content or a Google Cloud
	// Storage uri.
	//
	// Types that are assignable to AudioSource:
	//	*RecognitionAudio_Content
	//	*RecognitionAudio_Uri
	AudioSource isRecognitionAudio_AudioSource `protobuf_oneof:"audio_source"`
}

func (x *RecognitionAudio) Reset() {
	*x = RecognitionAudio{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[8]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *RecognitionAudio) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionAudio) ProtoMessage() {}

func (x *RecognitionAudio) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[8]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionAudio.ProtoReflect.Descriptor instead.
func (*RecognitionAudio) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{8}
}

func (m *RecognitionAudio) GetAudioSource() isRecognitionAudio_AudioSource {
	if m != nil {
		return m.AudioSource
	}
	return nil
}

func (x *RecognitionAudio) GetContent() []byte {
	if x, ok := x.GetAudioSource().(*RecognitionAudio_Content); ok {
		return x.Content
	}
	return nil
}

func (x *RecognitionAudio) GetUri() string {
	if x, ok := x.GetAudioSource().(*RecognitionAudio_Uri); ok {
		return x.Uri
	}
	return ""
}

type isRecognitionAudio_AudioSource interface {
	isRecognitionAudio_AudioSource()
}

type RecognitionAudio_Content struct {
	// The audio data bytes encoded as specified in
	// `RecognitionConfig`. Note: as with all bytes fields, proto buffers use a
	// pure binary representation, whereas JSON representations use base64.
	Content []byte `protobuf:"bytes,1,opt,name=content,proto3,oneof"`
}

type RecognitionAudio_Uri struct {
	// URI that points to a file that contains audio data bytes as specified in
	// `RecognitionConfig`. The file must not be compressed (for example, gzip).
	// Currently, only Google Cloud Storage URIs are
	// supported, which must be specified in the following format:
	// `gs://bucket_name/object_name` (other URI formats return
	// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more information, see
	// [Request URIs](https://cloud.google.com/storage/docs/reference-uris).
	Uri string `protobuf:"bytes,2,opt,name=uri,proto3,oneof"`
}

func (*RecognitionAudio_Content) isRecognitionAudio_AudioSource() {}

func (*RecognitionAudio_Uri) isRecognitionAudio_AudioSource() {}

// The only message returned to the client by the `Recognize` method. It
// contains the result as zero or more sequential `SpeechRecognitionResult`
// messages.
type RecognizeResponse struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Sequential list of transcription results corresponding to
	// sequential portions of audio.
	Results []*SpeechRecognitionResult `protobuf:"bytes,2,rep,name=results,proto3" json:"results,omitempty"`
}

func (x *RecognizeResponse) Reset() {
	*x = RecognizeResponse{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[9]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *RecognizeResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognizeResponse) ProtoMessage() {}

func (x *RecognizeResponse) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[9]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognizeResponse.ProtoReflect.Descriptor instead.
func (*RecognizeResponse) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{9}
}

func (x *RecognizeResponse) GetResults() []*SpeechRecognitionResult {
	if x != nil {
		return x.Results
	}
	return nil
}

// The only message returned to the client by the `LongRunningRecognize` method.
// It contains the result as zero or more sequential `SpeechRecognitionResult`
// messages. It is included in the `result.response` field of the `Operation`
// returned by the `GetOperation` call of the `google::longrunning::Operations`
// service.
type LongRunningRecognizeResponse struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Sequential list of transcription results corresponding to
	// sequential portions of audio.
	Results []*SpeechRecognitionResult `protobuf:"bytes,2,rep,name=results,proto3" json:"results,omitempty"`
}

func (x *LongRunningRecognizeResponse) Reset() {
	*x = LongRunningRecognizeResponse{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[10]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *LongRunningRecognizeResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LongRunningRecognizeResponse) ProtoMessage() {}

func (x *LongRunningRecognizeResponse) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[10]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LongRunningRecognizeResponse.ProtoReflect.Descriptor instead.
func (*LongRunningRecognizeResponse) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{10}
}

func (x *LongRunningRecognizeResponse) GetResults() []*SpeechRecognitionResult {
	if x != nil {
		return x.Results
	}
	return nil
}

// Describes the progress of a long-running `LongRunningRecognize` call. It is
// included in the `metadata` field of the `Operation` returned by the
// `GetOperation` call of the `google::longrunning::Operations` service.
type LongRunningRecognizeMetadata struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Approximate percentage of audio processed thus far. Guaranteed to be 100
	// when the audio is fully processed and the results are available.
	ProgressPercent int32 `protobuf:"varint,1,opt,name=progress_percent,json=progressPercent,proto3" json:"progress_percent,omitempty"`
	// Time when the request was received.
	StartTime *timestamppb.Timestamp `protobuf:"bytes,2,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`
	// Time of the most recent processing update.
	LastUpdateTime *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=last_update_time,json=lastUpdateTime,proto3" json:"last_update_time,omitempty"`
}

func (x *LongRunningRecognizeMetadata) Reset() {
	*x = LongRunningRecognizeMetadata{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[11]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *LongRunningRecognizeMetadata) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LongRunningRecognizeMetadata) ProtoMessage() {}

func (x *LongRunningRecognizeMetadata) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[11]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LongRunningRecognizeMetadata.ProtoReflect.Descriptor instead.
func (*LongRunningRecognizeMetadata) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{11}
}

func (x *LongRunningRecognizeMetadata) GetProgressPercent() int32 {
	if x != nil {
		return x.ProgressPercent
	}
	return 0
}

func (x *LongRunningRecognizeMetadata) GetStartTime() *timestamppb.Timestamp {
	if x != nil {
		return x.StartTime
	}
	return nil
}

func (x *LongRunningRecognizeMetadata) GetLastUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.LastUpdateTime
	}
	return nil
}

// `StreamingRecognizeResponse` is the only message returned to the client by
// `StreamingRecognize`. A series of zero or more `StreamingRecognizeResponse`
// messages are streamed back to the client. If there is no recognizable
// audio, and `single_utterance` is set to false, then no messages are streamed
// back to the client.
//
// Here's an example of a series of ten `StreamingRecognizeResponse`s that might
// be returned while processing audio:
//
// 1. results { alternatives { transcript: "tube" } stability: 0.01 }
//
// 2. results { alternatives { transcript: "to be a" } stability: 0.01 }
//
// 3. results { alternatives { transcript: "to be" } stability: 0.9 }
//    results { alternatives { transcript: " or not to be" } stability: 0.01 }
//
// 4. results { alternatives { transcript: "to be or not to be"
//                             confidence: 0.92 }
//              alternatives { transcript: "to bee or not to bee" }
//              is_final: true }
//
// 5. results { alternatives { transcript: " that's" } stability: 0.01 }
//
// 6. results { alternatives { transcript: " that is" } stability: 0.9 }
//    results { alternatives { transcript: " the question" } stability: 0.01 }
//
// 7. results { alternatives { transcript: " that is the question"
//                             confidence: 0.98 }
//              alternatives { transcript: " that was the question" }
//              is_final: true }
//
// Notes:
//
// - Only two of the above responses #4 and #7 contain final results; they are
//   indicated by `is_final: true`. Concatenating these together generates the
//   full transcript: "to be or not to be that is the question".
//
// - The others contain interim `results`. #3 and #6 contain two interim
//   `results`: the first portion has a high stability and is less likely to
//   change; the second portion has a low stability and is very likely to
//   change. A UI designer might choose to show only high stability `results`.
//
// - The specific `stability` and `confidence` values shown above are only for
//   illustrative purposes. Actual values may vary.
//
// - In each response, only one of these fields will be set:
//     `error`,
//     `speech_event_type`, or
//     one or more (repeated) `results`.
type StreamingRecognizeResponse struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// If set, returns a [google.rpc.Status][google.rpc.Status] message that
	// specifies the error for the operation.
	Error *status.Status `protobuf:"bytes,1,opt,name=error,proto3" json:"error,omitempty"`
	// This repeated list contains zero or more results that
	// correspond to consecutive portions of the audio currently being processed.
	// It contains zero or one `is_final=true` result (the newly settled portion),
	// followed by zero or more `is_final=false` results (the interim results).
	Results []*StreamingRecognitionResult `protobuf:"bytes,2,rep,name=results,proto3" json:"results,omitempty"`
	// Indicates the type of speech event.
	SpeechEventType StreamingRecognizeResponse_SpeechEventType `protobuf:"varint,4,opt,name=speech_event_type,json=speechEventType,proto3,enum=google.cloud.speech.v1.StreamingRecognizeResponse_SpeechEventType" json:"speech_event_type,omitempty"`
}

func (x *StreamingRecognizeResponse) Reset() {
	*x = StreamingRecognizeResponse{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[12]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *StreamingRecognizeResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamingRecognizeResponse) ProtoMessage() {}

func (x *StreamingRecognizeResponse) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[12]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamingRecognizeResponse.ProtoReflect.Descriptor instead.
func (*StreamingRecognizeResponse) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{12}
}

func (x *StreamingRecognizeResponse) GetError() *status.Status {
	if x != nil {
		return x.Error
	}
	return nil
}

func (x *StreamingRecognizeResponse) GetResults() []*StreamingRecognitionResult {
	if x != nil {
		return x.Results
	}
	return nil
}

func (x *StreamingRecognizeResponse) GetSpeechEventType() StreamingRecognizeResponse_SpeechEventType {
	if x != nil {
		return x.SpeechEventType
	}
	return StreamingRecognizeResponse_SPEECH_EVENT_UNSPECIFIED
}

// A streaming speech recognition result corresponding to a portion of the audio
// that is currently being processed.
type StreamingRecognitionResult struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// May contain one or more recognition hypotheses (up to the
	// maximum specified in `max_alternatives`).
	// These alternatives are ordered in terms of accuracy, with the top (first)
	// alternative being the most probable, as ranked by the recognizer.
	Alternatives []*SpeechRecognitionAlternative `protobuf:"bytes,1,rep,name=alternatives,proto3" json:"alternatives,omitempty"`
	// If `false`, this `StreamingRecognitionResult` represents an
	// interim result that may change. If `true`, this is the final time the
	// speech service will return this particular `StreamingRecognitionResult`,
	// the recognizer will not return any further hypotheses for this portion of
	// the transcript and corresponding audio.
	IsFinal bool `protobuf:"varint,2,opt,name=is_final,json=isFinal,proto3" json:"is_final,omitempty"`
	// An estimate of the likelihood that the recognizer will not
	// change its guess about this interim result. Values range from 0.0
	// (completely unstable) to 1.0 (completely stable).
	// This field is only provided for interim results (`is_final=false`).
	// The default of 0.0 is a sentinel value indicating `stability` was not set.
	Stability float32 `protobuf:"fixed32,3,opt,name=stability,proto3" json:"stability,omitempty"`
	// Time offset of the end of this result relative to the
	// beginning of the audio.
	ResultEndTime *durationpb.Duration `protobuf:"bytes,4,opt,name=result_end_time,json=resultEndTime,proto3" json:"result_end_time,omitempty"`
	// For multi-channel audio, this is the channel number corresponding to the
	// recognized result for the audio from that channel.
	// For audio_channel_count = N, its output values can range from '1' to 'N'.
	ChannelTag int32 `protobuf:"varint,5,opt,name=channel_tag,json=channelTag,proto3" json:"channel_tag,omitempty"`
	// The [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag of
	// the language in this result. This language code was detected to have the
	// most likelihood of being spoken in the audio.
	LanguageCode string `protobuf:"bytes,6,opt,name=language_code,json=languageCode,proto3" json:"language_code,omitempty"`
}

func (x *StreamingRecognitionResult) Reset() {
	*x = StreamingRecognitionResult{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[13]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *StreamingRecognitionResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamingRecognitionResult) ProtoMessage() {}

func (x *StreamingRecognitionResult) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[13]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamingRecognitionResult.ProtoReflect.Descriptor instead.
func (*StreamingRecognitionResult) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{13}
}

func (x *StreamingRecognitionResult) GetAlternatives() []*SpeechRecognitionAlternative {
	if x != nil {
		return x.Alternatives
	}
	return nil
}

func (x *StreamingRecognitionResult) GetIsFinal() bool {
	if x != nil {
		return x.IsFinal
	}
	return false
}

func (x *StreamingRecognitionResult) GetStability() float32 {
	if x != nil {
		return x.Stability
	}
	return 0
}

func (x *StreamingRecognitionResult) GetResultEndTime() *durationpb.Duration {
	if x != nil {
		return x.ResultEndTime
	}
	return nil
}

func (x *StreamingRecognitionResult) GetChannelTag() int32 {
	if x != nil {
		return x.ChannelTag
	}
	return 0
}

func (x *StreamingRecognitionResult) GetLanguageCode() string {
	if x != nil {
		return x.LanguageCode
	}
	return ""
}

// A speech recognition result corresponding to a portion of the audio.
type SpeechRecognitionResult struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// May contain one or more recognition hypotheses (up to the
	// maximum specified in `max_alternatives`).
	// These alternatives are ordered in terms of accuracy, with the top (first)
	// alternative being the most probable, as ranked by the recognizer.
	Alternatives []*SpeechRecognitionAlternative `protobuf:"bytes,1,rep,name=alternatives,proto3" json:"alternatives,omitempty"`
	// For multi-channel audio, this is the channel number corresponding to the
	// recognized result for the audio from that channel.
	// For audio_channel_count = N, its output values can range from '1' to 'N'.
	ChannelTag int32 `protobuf:"varint,2,opt,name=channel_tag,json=channelTag,proto3" json:"channel_tag,omitempty"`
}

func (x *SpeechRecognitionResult) Reset() {
	*x = SpeechRecognitionResult{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[14]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *SpeechRecognitionResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechRecognitionResult) ProtoMessage() {}

func (x *SpeechRecognitionResult) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[14]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SpeechRecognitionResult.ProtoReflect.Descriptor instead.
func (*SpeechRecognitionResult) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{14}
}

func (x *SpeechRecognitionResult) GetAlternatives() []*SpeechRecognitionAlternative {
	if x != nil {
		return x.Alternatives
	}
	return nil
}

func (x *SpeechRecognitionResult) GetChannelTag() int32 {
	if x != nil {
		return x.ChannelTag
	}
	return 0
}

// Alternative hypotheses (a.k.a. n-best list).
type SpeechRecognitionAlternative struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Transcript text representing the words that the user spoke.
	Transcript string `protobuf:"bytes,1,opt,name=transcript,proto3" json:"transcript,omitempty"`
	// The confidence estimate between 0.0 and 1.0. A higher number
	// indicates an estimated greater likelihood that the recognized words are
	// correct. This field is set only for the top alternative of a non-streaming
	// result or, of a streaming result where `is_final=true`.
	// This field is not guaranteed to be accurate and users should not rely on it
	// to be always provided.
	// The default of 0.0 is a sentinel value indicating `confidence` was not set.
	Confidence float32 `protobuf:"fixed32,2,opt,name=confidence,proto3" json:"confidence,omitempty"`
	// A list of word-specific information for each recognized word.
	// Note: When `enable_speaker_diarization` is true, you will see all the words
	// from the beginning of the audio.
	Words []*WordInfo `protobuf:"bytes,3,rep,name=words,proto3" json:"words,omitempty"`
}

func (x *SpeechRecognitionAlternative) Reset() {
	*x = SpeechRecognitionAlternative{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[15]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *SpeechRecognitionAlternative) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechRecognitionAlternative) ProtoMessage() {}

func (x *SpeechRecognitionAlternative) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[15]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SpeechRecognitionAlternative.ProtoReflect.Descriptor instead.
func (*SpeechRecognitionAlternative) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{15}
}

func (x *SpeechRecognitionAlternative) GetTranscript() string {
	if x != nil {
		return x.Transcript
	}
	return ""
}

func (x *SpeechRecognitionAlternative) GetConfidence() float32 {
	if x != nil {
		return x.Confidence
	}
	return 0
}

func (x *SpeechRecognitionAlternative) GetWords() []*WordInfo {
	if x != nil {
		return x.Words
	}
	return nil
}

// Word-specific information for recognized words.
type WordInfo struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Time offset relative to the beginning of the audio,
	// and corresponding to the start of the spoken word.
	// This field is only set if `enable_word_time_offsets=true` and only
	// in the top hypothesis.
	// This is an experimental feature and the accuracy of the time offset can
	// vary.
	StartTime *durationpb.Duration `protobuf:"bytes,1,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`
	// Time offset relative to the beginning of the audio,
	// and corresponding to the end of the spoken word.
	// This field is only set if `enable_word_time_offsets=true` and only
	// in the top hypothesis.
	// This is an experimental feature and the accuracy of the time offset can
	// vary.
	EndTime *durationpb.Duration `protobuf:"bytes,2,opt,name=end_time,json=endTime,proto3" json:"end_time,omitempty"`
	// The word corresponding to this set of information.
	Word string `protobuf:"bytes,3,opt,name=word,proto3" json:"word,omitempty"`
	// A distinct integer value is assigned for every speaker within
	// the audio. This field specifies which one of those speakers was detected to
	// have spoken this word. Value ranges from '1' to diarization_speaker_count.
	// speaker_tag is set if enable_speaker_diarization = 'true' and only in the
	// top alternative.
	SpeakerTag int32 `protobuf:"varint,5,opt,name=speaker_tag,json=speakerTag,proto3" json:"speaker_tag,omitempty"`
}

func (x *WordInfo) Reset() {
	*x = WordInfo{}
	if protoimpl.UnsafeEnabled {
		mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[16]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *WordInfo) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*WordInfo) ProtoMessage() {}

func (x *WordInfo) ProtoReflect() protoreflect.Message {
	mi := &file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[16]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use WordInfo.ProtoReflect.Descriptor instead.
func (*WordInfo) Descriptor() ([]byte, []int) {
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP(), []int{16}
}

func (x *WordInfo) GetStartTime() *durationpb.Duration {
	if x != nil {
		return x.StartTime
	}
	return nil
}

func (x *WordInfo) GetEndTime() *durationpb.Duration {
	if x != nil {
		return x.EndTime
	}
	return nil
}

func (x *WordInfo) GetWord() string {
	if x != nil {
		return x.Word
	}
	return ""
}

func (x *WordInfo) GetSpeakerTag() int32 {
	if x != nil {
		return x.SpeakerTag
	}
	return 0
}

var File_google_cloud_speech_v1_cloud_speech_proto protoreflect.FileDescriptor

var file_google_cloud_speech_v1_cloud_speech_proto_rawDesc = []byte{
	0x0a, 0x29, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2f, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2f, 0x73,
	0x70, 0x65, 0x65, 0x63, 0x68, 0x2f, 0x76, 0x31, 0x2f, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x5f, 0x73,
	0x70, 0x65, 0x65, 0x63, 0x68, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x12, 0x16, 0x67, 0x6f, 0x6f,
	0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68,
	0x2e, 0x76, 0x31, 0x1a, 0x1c, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2f, 0x61, 0x70, 0x69, 0x2f,
	0x61, 0x6e, 0x6e, 0x6f, 0x74, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x73, 0x2e, 0x70, 0x72, 0x6f, 0x74,
	0x6f, 0x1a, 0x17, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2f, 0x61, 0x70, 0x69, 0x2f, 0x63, 0x6c,
	0x69, 0x65, 0x6e, 0x74, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x1a, 0x1f, 0x67, 0x6f, 0x6f, 0x67,
	0x6c, 0x65, 0x2f, 0x61, 0x70, 0x69, 0x2f, 0x66, 0x69, 0x65, 0x6c, 0x64, 0x5f, 0x62, 0x65, 0x68,
	0x61, 0x76, 0x69, 0x6f, 0x72, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x1a, 0x23, 0x67, 0x6f, 0x6f,
	0x67, 0x6c, 0x65, 0x2f, 0x6c, 0x6f, 0x6e, 0x67, 0x72, 0x75, 0x6e, 0x6e, 0x69, 0x6e, 0x67, 0x2f,
	0x6f, 0x70, 0x65, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x73, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f,
	0x1a, 0x19, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62, 0x75,
	0x66, 0x2f, 0x61, 0x6e, 0x79, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x1a, 0x1e, 0x67, 0x6f, 0x6f,
	0x67, 0x6c, 0x65, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62, 0x75, 0x66, 0x2f, 0x64, 0x75, 0x72,
	0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x1a, 0x1f, 0x67, 0x6f, 0x6f,
	0x67, 0x6c, 0x65, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62, 0x75, 0x66, 0x2f, 0x74, 0x69, 0x6d,
	0x65, 0x73, 0x74, 0x61, 0x6d, 0x70, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x1a, 0x17, 0x67, 0x6f,
	0x6f, 0x67, 0x6c, 0x65, 0x2f, 0x72, 0x70, 0x63, 0x2f, 0x73, 0x74, 0x61, 0x74, 0x75, 0x73, 0x2e,
	0x70, 0x72, 0x6f, 0x74, 0x6f, 0x22, 0x9f, 0x01, 0x0a, 0x10, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e,
	0x69, 0x7a, 0x65, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x12, 0x46, 0x0a, 0x06, 0x63, 0x6f,
	0x6e, 0x66, 0x69, 0x67, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x29, 0x2e, 0x67, 0x6f, 0x6f,
	0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68,
	0x2e, 0x76, 0x31, 0x2e, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x43,
	0x6f, 0x6e, 0x66, 0x69, 0x67, 0x42, 0x03, 0xe0, 0x41, 0x02, 0x52, 0x06, 0x63, 0x6f, 0x6e, 0x66,
	0x69, 0x67, 0x12, 0x43, 0x0a, 0x05, 0x61, 0x75, 0x64, 0x69, 0x6f, 0x18, 0x02, 0x20, 0x01, 0x28,
	0x0b, 0x32, 0x28, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64,
	0x2e, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x52, 0x65, 0x63, 0x6f, 0x67,
	0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x41, 0x75, 0x64, 0x69, 0x6f, 0x42, 0x03, 0xe0, 0x41, 0x02,
	0x52, 0x05, 0x61, 0x75, 0x64, 0x69, 0x6f, 0x22, 0xaa, 0x01, 0x0a, 0x1b, 0x4c, 0x6f, 0x6e, 0x67,
	0x52, 0x75, 0x6e, 0x6e, 0x69, 0x6e, 0x67, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x7a, 0x65,
	0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x12, 0x46, 0x0a, 0x06, 0x63, 0x6f, 0x6e, 0x66, 0x69,
	0x67, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x29, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65,
	0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31,
	0x2e, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x43, 0x6f, 0x6e, 0x66,
	0x69, 0x67, 0x42, 0x03, 0xe0, 0x41, 0x02, 0x52, 0x06, 0x63, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x12,
	0x43, 0x0a, 0x05, 0x61, 0x75, 0x64, 0x69, 0x6f, 0x18, 0x02, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x28,
	0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70,
	0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74,
	0x69, 0x6f, 0x6e, 0x41, 0x75, 0x64, 0x69, 0x6f, 0x42, 0x03, 0xe0, 0x41, 0x02, 0x52, 0x05, 0x61,
	0x75, 0x64, 0x69, 0x6f, 0x22, 0xb8, 0x01, 0x0a, 0x19, 0x53, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x69,
	0x6e, 0x67, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x7a, 0x65, 0x52, 0x65, 0x71, 0x75, 0x65,
	0x73, 0x74, 0x12, 0x5f, 0x0a, 0x10, 0x73, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x69, 0x6e, 0x67, 0x5f,
	0x63, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x32, 0x2e, 0x67,
	0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65,
	0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x53, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x69, 0x6e, 0x67, 0x52,
	0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x43, 0x6f, 0x6e, 0x66, 0x69, 0x67,
	0x48, 0x00, 0x52, 0x0f, 0x73, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x69, 0x6e, 0x67, 0x43, 0x6f, 0x6e,
	0x66, 0x69, 0x67, 0x12, 0x25, 0x0a, 0x0d, 0x61, 0x75, 0x64, 0x69, 0x6f, 0x5f, 0x63, 0x6f, 0x6e,
	0x74, 0x65, 0x6e, 0x74, 0x18, 0x02, 0x20, 0x01, 0x28, 0x0c, 0x48, 0x00, 0x52, 0x0c, 0x61, 0x75,
	0x64, 0x69, 0x6f, 0x43, 0x6f, 0x6e, 0x74, 0x65, 0x6e, 0x74, 0x42, 0x13, 0x0a, 0x11, 0x73, 0x74,
	0x72, 0x65, 0x61, 0x6d, 0x69, 0x6e, 0x67, 0x5f, 0x72, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x22,
	0xb8, 0x01, 0x0a, 0x1a, 0x53, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x69, 0x6e, 0x67, 0x52, 0x65, 0x63,
	0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x43, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x12, 0x46,
	0x0a, 0x06, 0x63, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x29,
	0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70,
	0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74,
	0x69, 0x6f, 0x6e, 0x43, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x42, 0x03, 0xe0, 0x41, 0x02, 0x52, 0x06,
	0x63, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x12, 0x29, 0x0a, 0x10, 0x73, 0x69, 0x6e, 0x67, 0x6c, 0x65,
	0x5f, 0x75, 0x74, 0x74, 0x65, 0x72, 0x61, 0x6e, 0x63, 0x65, 0x18, 0x02, 0x20, 0x01, 0x28, 0x08,
	0x52, 0x0f, 0x73, 0x69, 0x6e, 0x67, 0x6c, 0x65, 0x55, 0x74, 0x74, 0x65, 0x72, 0x61, 0x6e, 0x63,
	0x65, 0x12, 0x27, 0x0a, 0x0f, 0x69, 0x6e, 0x74, 0x65, 0x72, 0x69, 0x6d, 0x5f, 0x72, 0x65, 0x73,
	0x75, 0x6c, 0x74, 0x73, 0x18, 0x03, 0x20, 0x01, 0x28, 0x08, 0x52, 0x0e, 0x69, 0x6e, 0x74, 0x65,
	0x72, 0x69, 0x6d, 0x52, 0x65, 0x73, 0x75, 0x6c, 0x74, 0x73, 0x22, 0xd6, 0x07, 0x0a, 0x11, 0x52,
	0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x43, 0x6f, 0x6e, 0x66, 0x69, 0x67,
	0x12, 0x53, 0x0a, 0x08, 0x65, 0x6e, 0x63, 0x6f, 0x64, 0x69, 0x6e, 0x67, 0x18, 0x01, 0x20, 0x01,
	0x28, 0x0e, 0x32, 0x37, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75,
	0x64, 0x2e, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x52, 0x65, 0x63, 0x6f,
	0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x43, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x2e, 0x41, 0x75,
	0x64, 0x69, 0x6f, 0x45, 0x6e, 0x63, 0x6f, 0x64, 0x69, 0x6e, 0x67, 0x52, 0x08, 0x65, 0x6e, 0x63,
	0x6f, 0x64, 0x69, 0x6e, 0x67, 0x12, 0x2a, 0x0a, 0x11, 0x73, 0x61, 0x6d, 0x70, 0x6c, 0x65, 0x5f,
	0x72, 0x61, 0x74, 0x65, 0x5f, 0x68, 0x65, 0x72, 0x74, 0x7a, 0x18, 0x02, 0x20, 0x01, 0x28, 0x05,
	0x52, 0x0f, 0x73, 0x61, 0x6d, 0x70, 0x6c, 0x65, 0x52, 0x61, 0x74, 0x65, 0x48, 0x65, 0x72, 0x74,
	0x7a, 0x12, 0x2e, 0x0a, 0x13, 0x61, 0x75, 0x64, 0x69, 0x6f, 0x5f, 0x63, 0x68, 0x61, 0x6e, 0x6e,
	0x65, 0x6c, 0x5f, 0x63, 0x6f, 0x75, 0x6e, 0x74, 0x18, 0x07, 0x20, 0x01, 0x28, 0x05, 0x52, 0x11,
	0x61, 0x75, 0x64, 0x69, 0x6f, 0x43, 0x68, 0x61, 0x6e, 0x6e, 0x65, 0x6c, 0x43, 0x6f, 0x75, 0x6e,
	0x74, 0x12, 0x54, 0x0a, 0x27, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x73, 0x65, 0x70, 0x61,
	0x72, 0x61, 0x74, 0x65, 0x5f, 0x72, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e,
	0x5f, 0x70, 0x65, 0x72, 0x5f, 0x63, 0x68, 0x61, 0x6e, 0x6e, 0x65, 0x6c, 0x18, 0x0c, 0x20, 0x01,
	0x28, 0x08, 0x52, 0x23, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x53, 0x65, 0x70, 0x61, 0x72, 0x61,
	0x74, 0x65, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x50, 0x65, 0x72,
	0x43, 0x68, 0x61, 0x6e, 0x6e, 0x65, 0x6c, 0x12, 0x28, 0x0a, 0x0d, 0x6c, 0x61, 0x6e, 0x67, 0x75,
	0x61, 0x67, 0x65, 0x5f, 0x63, 0x6f, 0x64, 0x65, 0x18, 0x03, 0x20, 0x01, 0x28, 0x09, 0x42, 0x03,
	0xe0, 0x41, 0x02, 0x52, 0x0c, 0x6c, 0x61, 0x6e, 0x67, 0x75, 0x61, 0x67, 0x65, 0x43, 0x6f, 0x64,
	0x65, 0x12, 0x29, 0x0a, 0x10, 0x6d, 0x61, 0x78, 0x5f, 0x61, 0x6c, 0x74, 0x65, 0x72, 0x6e, 0x61,
	0x74, 0x69, 0x76, 0x65, 0x73, 0x18, 0x04, 0x20, 0x01, 0x28, 0x05, 0x52, 0x0f, 0x6d, 0x61, 0x78,
	0x41, 0x6c, 0x74, 0x65, 0x72, 0x6e, 0x61, 0x74, 0x69, 0x76, 0x65, 0x73, 0x12, 0x29, 0x0a, 0x10,
	0x70, 0x72, 0x6f, 0x66, 0x61, 0x6e, 0x69, 0x74, 0x79, 0x5f, 0x66, 0x69, 0x6c, 0x74, 0x65, 0x72,
	0x18, 0x05, 0x20, 0x01, 0x28, 0x08, 0x52, 0x0f, 0x70, 0x72, 0x6f, 0x66, 0x61, 0x6e, 0x69, 0x74,
	0x79, 0x46, 0x69, 0x6c, 0x74, 0x65, 0x72, 0x12, 0x4e, 0x0a, 0x0f, 0x73, 0x70, 0x65, 0x65, 0x63,
	0x68, 0x5f, 0x63, 0x6f, 0x6e, 0x74, 0x65, 0x78, 0x74, 0x73, 0x18, 0x06, 0x20, 0x03, 0x28, 0x0b,
	0x32, 0x25, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e,
	0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x53, 0x70, 0x65, 0x65, 0x63, 0x68,
	0x43, 0x6f, 0x6e, 0x74, 0x65, 0x78, 0x74, 0x52, 0x0e, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x43,
	0x6f, 0x6e, 0x74, 0x65, 0x78, 0x74, 0x73, 0x12, 0x37, 0x0a, 0x18, 0x65, 0x6e, 0x61, 0x62, 0x6c,
	0x65, 0x5f, 0x77, 0x6f, 0x72, 0x64, 0x5f, 0x74, 0x69, 0x6d, 0x65, 0x5f, 0x6f, 0x66, 0x66, 0x73,
	0x65, 0x74, 0x73, 0x18, 0x08, 0x20, 0x01, 0x28, 0x08, 0x52, 0x15, 0x65, 0x6e, 0x61, 0x62, 0x6c,
	0x65, 0x57, 0x6f, 0x72, 0x64, 0x54, 0x69, 0x6d, 0x65, 0x4f, 0x66, 0x66, 0x73, 0x65, 0x74, 0x73,
	0x12, 0x40, 0x0a, 0x1c, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x61, 0x75, 0x74, 0x6f, 0x6d,
	0x61, 0x74, 0x69, 0x63, 0x5f, 0x70, 0x75, 0x6e, 0x63, 0x74, 0x75, 0x61, 0x74, 0x69, 0x6f, 0x6e,
	0x18, 0x0b, 0x20, 0x01, 0x28, 0x08, 0x52, 0x1a, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x41, 0x75,
	0x74, 0x6f, 0x6d, 0x61, 0x74, 0x69, 0x63, 0x50, 0x75, 0x6e, 0x63, 0x74, 0x75, 0x61, 0x74, 0x69,
	0x6f, 0x6e, 0x12, 0x5f, 0x0a, 0x12, 0x64, 0x69, 0x61, 0x72, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f,
	0x6e, 0x5f, 0x63, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x18, 0x13, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x30,
	0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70,
	0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x53, 0x70, 0x65, 0x61, 0x6b, 0x65, 0x72, 0x44,
	0x69, 0x61, 0x72, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x43, 0x6f, 0x6e, 0x66, 0x69, 0x67,
	0x52, 0x11, 0x64, 0x69, 0x61, 0x72, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x43, 0x6f, 0x6e,
	0x66, 0x69, 0x67, 0x12, 0x47, 0x0a, 0x08, 0x6d, 0x65, 0x74, 0x61, 0x64, 0x61, 0x74, 0x61, 0x18,
	0x09, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x2b, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63,
	0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x52,
	0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x4d, 0x65, 0x74, 0x61, 0x64, 0x61,
	0x74, 0x61, 0x52, 0x08, 0x6d, 0x65, 0x74, 0x61, 0x64, 0x61, 0x74, 0x61, 0x12, 0x14, 0x0a, 0x05,
	0x6d, 0x6f, 0x64, 0x65, 0x6c, 0x18, 0x0d, 0x20, 0x01, 0x28, 0x09, 0x52, 0x05, 0x6d, 0x6f, 0x64,
	0x65, 0x6c, 0x12, 0x21, 0x0a, 0x0c, 0x75, 0x73, 0x65, 0x5f, 0x65, 0x6e, 0x68, 0x61, 0x6e, 0x63,
	0x65, 0x64, 0x18, 0x0e, 0x20, 0x01, 0x28, 0x08, 0x52, 0x0b, 0x75, 0x73, 0x65, 0x45, 0x6e, 0x68,
	0x61, 0x6e, 0x63, 0x65, 0x64, 0x22, 0x8b, 0x01, 0x0a, 0x0d, 0x41, 0x75, 0x64, 0x69, 0x6f, 0x45,
	0x6e, 0x63, 0x6f, 0x64, 0x69, 0x6e, 0x67, 0x12, 0x18, 0x0a, 0x14, 0x45, 0x4e, 0x43, 0x4f, 0x44,
	0x49, 0x4e, 0x47, 0x5f, 0x55, 0x4e, 0x53, 0x50, 0x45, 0x43, 0x49, 0x46, 0x49, 0x45, 0x44, 0x10,
	0x00, 0x12, 0x0c, 0x0a, 0x08, 0x4c, 0x49, 0x4e, 0x45, 0x41, 0x52, 0x31, 0x36, 0x10, 0x01, 0x12,
	0x08, 0x0a, 0x04, 0x46, 0x4c, 0x41, 0x43, 0x10, 0x02, 0x12, 0x09, 0x0a, 0x05, 0x4d, 0x55, 0x4c,
	0x41, 0x57, 0x10, 0x03, 0x12, 0x07, 0x0a, 0x03, 0x41, 0x4d, 0x52, 0x10, 0x04, 0x12, 0x0a, 0x0a,
	0x06, 0x41, 0x4d, 0x52, 0x5f, 0x57, 0x42, 0x10, 0x05, 0x12, 0x0c, 0x0a, 0x08, 0x4f, 0x47, 0x47,
	0x5f, 0x4f, 0x50, 0x55, 0x53, 0x10, 0x06, 0x12, 0x1a, 0x0a, 0x16, 0x53, 0x50, 0x45, 0x45, 0x58,
	0x5f, 0x57, 0x49, 0x54, 0x48, 0x5f, 0x48, 0x45, 0x41, 0x44, 0x45, 0x52, 0x5f, 0x42, 0x59, 0x54,
	0x45, 0x10, 0x07, 0x22, 0xd8, 0x01, 0x0a, 0x18, 0x53, 0x70, 0x65, 0x61, 0x6b, 0x65, 0x72, 0x44,
	0x69, 0x61, 0x72, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x43, 0x6f, 0x6e, 0x66, 0x69, 0x67,
	0x12, 0x3c, 0x0a, 0x1a, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x73, 0x70, 0x65, 0x61, 0x6b,
	0x65, 0x72, 0x5f, 0x64, 0x69, 0x61, 0x72, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x18, 0x01,
	0x20, 0x01, 0x28, 0x08, 0x52, 0x18, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x53, 0x70, 0x65, 0x61,
	0x6b, 0x65, 0x72, 0x44, 0x69, 0x61, 0x72, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x12, 0x2a,
	0x0a, 0x11, 0x6d, 0x69, 0x6e, 0x5f, 0x73, 0x70, 0x65, 0x61, 0x6b, 0x65, 0x72, 0x5f, 0x63, 0x6f,
	0x75, 0x6e, 0x74, 0x18, 0x02, 0x20, 0x01, 0x28, 0x05, 0x52, 0x0f, 0x6d, 0x69, 0x6e, 0x53, 0x70,
	0x65, 0x61, 0x6b, 0x65, 0x72, 0x43, 0x6f, 0x75, 0x6e, 0x74, 0x12, 0x2a, 0x0a, 0x11, 0x6d, 0x61,
	0x78, 0x5f, 0x73, 0x70, 0x65, 0x61, 0x6b, 0x65, 0x72, 0x5f, 0x63, 0x6f, 0x75, 0x6e, 0x74, 0x18,
	0x03, 0x20, 0x01, 0x28, 0x05, 0x52, 0x0f, 0x6d, 0x61, 0x78, 0x53, 0x70, 0x65, 0x61, 0x6b, 0x65,
	0x72, 0x43, 0x6f, 0x75, 0x6e, 0x74, 0x12, 0x26, 0x0a, 0x0b, 0x73, 0x70, 0x65, 0x61, 0x6b, 0x65,
	0x72, 0x5f, 0x74, 0x61, 0x67, 0x18, 0x05, 0x20, 0x01, 0x28, 0x05, 0x42, 0x05, 0x18, 0x01, 0xe0,
	0x41, 0x03, 0x52, 0x0a, 0x73, 0x70, 0x65, 0x61, 0x6b, 0x65, 0x72, 0x54, 0x61, 0x67, 0x22, 0xba,
	0x09, 0x0a, 0x13, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x4d, 0x65,
	0x74, 0x61, 0x64, 0x61, 0x74, 0x61, 0x12, 0x66, 0x0a, 0x10, 0x69, 0x6e, 0x74, 0x65, 0x72, 0x61,
	0x63, 0x74, 0x69, 0x6f, 0x6e, 0x5f, 0x74, 0x79, 0x70, 0x65, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0e,
	0x32, 0x3b, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e,
	0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e,
	0x69, 0x74, 0x69, 0x6f, 0x6e, 0x4d, 0x65, 0x74, 0x61, 0x64, 0x61, 0x74, 0x61, 0x2e, 0x49, 0x6e,
	0x74, 0x65, 0x72, 0x61, 0x63, 0x74, 0x69, 0x6f, 0x6e, 0x54, 0x79, 0x70, 0x65, 0x52, 0x0f, 0x69,
	0x6e, 0x74, 0x65, 0x72, 0x61, 0x63, 0x74, 0x69, 0x6f, 0x6e, 0x54, 0x79, 0x70, 0x65, 0x12, 0x3e,
	0x0a, 0x1c, 0x69, 0x6e, 0x64, 0x75, 0x73, 0x74, 0x72, 0x79, 0x5f, 0x6e, 0x61, 0x69, 0x63, 0x73,
	0x5f, 0x63, 0x6f, 0x64, 0x65, 0x5f, 0x6f, 0x66, 0x5f, 0x61, 0x75, 0x64, 0x69, 0x6f, 0x18, 0x03,
	0x20, 0x01, 0x28, 0x0d, 0x52, 0x18, 0x69, 0x6e, 0x64, 0x75, 0x73, 0x74, 0x72, 0x79, 0x4e, 0x61,
	0x69, 0x63, 0x73, 0x43, 0x6f, 0x64, 0x65, 0x4f, 0x66, 0x41, 0x75, 0x64, 0x69, 0x6f, 0x12, 0x6f,
	0x0a, 0x13, 0x6d, 0x69, 0x63, 0x72, 0x6f, 0x70, 0x68, 0x6f, 0x6e, 0x65, 0x5f, 0x64, 0x69, 0x73,
	0x74, 0x61, 0x6e, 0x63, 0x65, 0x18, 0x04, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x3e, 0x2e, 0x67, 0x6f,
	0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65, 0x63,
	0x68, 0x2e, 0x76, 0x31, 0x2e, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e,
	0x4d, 0x65, 0x74, 0x61, 0x64, 0x61, 0x74, 0x61, 0x2e, 0x4d, 0x69, 0x63, 0x72, 0x6f, 0x70, 0x68,
	0x6f, 0x6e, 0x65, 0x44, 0x69, 0x73, 0x74, 0x61, 0x6e, 0x63, 0x65, 0x52, 0x12, 0x6d, 0x69, 0x63,
	0x72, 0x6f, 0x70, 0x68, 0x6f, 0x6e, 0x65, 0x44, 0x69, 0x73, 0x74, 0x61, 0x6e, 0x63, 0x65, 0x12,
	0x6d, 0x0a, 0x13, 0x6f, 0x72, 0x69, 0x67, 0x69, 0x6e, 0x61, 0x6c, 0x5f, 0x6d, 0x65, 0x64, 0x69,
	0x61, 0x5f, 0x74, 0x79, 0x70, 0x65, 0x18, 0x05, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x3d, 0x2e, 0x67,
	0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65,
	0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f,
	0x6e, 0x4d, 0x65, 0x74, 0x61, 0x64, 0x61, 0x74, 0x61, 0x2e, 0x4f, 0x72, 0x69, 0x67, 0x69, 0x6e,
	0x61, 0x6c, 0x4d, 0x65, 0x64, 0x69, 0x61, 0x54, 0x79, 0x70, 0x65, 0x52, 0x11, 0x6f, 0x72, 0x69,
	0x67, 0x69, 0x6e, 0x61, 0x6c, 0x4d, 0x65, 0x64, 0x69, 0x61, 0x54, 0x79, 0x70, 0x65, 0x12, 0x73,
	0x0a, 0x15, 0x72, 0x65, 0x63, 0x6f, 0x72, 0x64, 0x69, 0x6e, 0x67, 0x5f, 0x64, 0x65, 0x76, 0x69,
	0x63, 0x65, 0x5f, 0x74, 0x79, 0x70, 0x65, 0x18, 0x06, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x3f, 0x2e,
	0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65,
	0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69,
	0x6f, 0x6e, 0x4d, 0x65, 0x74, 0x61, 0x64, 0x61, 0x74, 0x61, 0x2e, 0x52, 0x65, 0x63, 0x6f, 0x72,
	0x64, 0x69, 0x6e, 0x67, 0x44, 0x65, 0x76, 0x69, 0x63, 0x65, 0x54, 0x79, 0x70, 0x65, 0x52, 0x13,
	0x72, 0x65, 0x63, 0x6f, 0x72, 0x64, 0x69, 0x6e, 0x67, 0x44, 0x65, 0x76, 0x69, 0x63, 0x65, 0x54,
	0x79, 0x70, 0x65, 0x12, 0x32, 0x0a, 0x15, 0x72, 0x65, 0x63, 0x6f, 0x72, 0x64, 0x69, 0x6e, 0x67,
	0x5f, 0x64, 0x65, 0x76, 0x69, 0x63, 0x65, 0x5f, 0x6e, 0x61, 0x6d, 0x65, 0x18, 0x07, 0x20, 0x01,
	0x28, 0x09, 0x52, 0x13, 0x72, 0x65, 0x63, 0x6f, 0x72, 0x64, 0x69, 0x6e, 0x67, 0x44, 0x65, 0x76,
	0x69, 0x63, 0x65, 0x4e, 0x61, 0x6d, 0x65, 0x12, 0x2c, 0x0a, 0x12, 0x6f, 0x72, 0x69, 0x67, 0x69,
	0x6e, 0x61, 0x6c, 0x5f, 0x6d, 0x69, 0x6d, 0x65, 0x5f, 0x74, 0x79, 0x70, 0x65, 0x18, 0x08, 0x20,
	0x01, 0x28, 0x09, 0x52, 0x10, 0x6f, 0x72, 0x69, 0x67, 0x69, 0x6e, 0x61, 0x6c, 0x4d, 0x69, 0x6d,
	0x65, 0x54, 0x79, 0x70, 0x65, 0x12, 0x1f, 0x0a, 0x0b, 0x61, 0x75, 0x64, 0x69, 0x6f, 0x5f, 0x74,
	0x6f, 0x70, 0x69, 0x63, 0x18, 0x0a, 0x20, 0x01, 0x28, 0x09, 0x52, 0x0a, 0x61, 0x75, 0x64, 0x69,
	0x6f, 0x54, 0x6f, 0x70, 0x69, 0x63, 0x22, 0xc5, 0x01, 0x0a, 0x0f, 0x49, 0x6e, 0x74, 0x65, 0x72,
	0x61, 0x63, 0x74, 0x69, 0x6f, 0x6e, 0x54, 0x79, 0x70, 0x65, 0x12, 0x20, 0x0a, 0x1c, 0x49, 0x4e,
	0x54, 0x45, 0x52, 0x41, 0x43, 0x54, 0x49, 0x4f, 0x4e, 0x5f, 0x54, 0x59, 0x50, 0x45, 0x5f, 0x55,
	0x4e, 0x53, 0x50, 0x45, 0x43, 0x49, 0x46, 0x49, 0x45, 0x44, 0x10, 0x00, 0x12, 0x0e, 0x0a, 0x0a,
	0x44, 0x49, 0x53, 0x43, 0x55, 0x53, 0x53, 0x49, 0x4f, 0x4e, 0x10, 0x01, 0x12, 0x10, 0x0a, 0x0c,
	0x50, 0x52, 0x45, 0x53, 0x45, 0x4e, 0x54, 0x41, 0x54, 0x49, 0x4f, 0x4e, 0x10, 0x02, 0x12, 0x0e,
	0x0a, 0x0a, 0x50, 0x48, 0x4f, 0x4e, 0x45, 0x5f, 0x43, 0x41, 0x4c, 0x4c, 0x10, 0x03, 0x12, 0x0d,
	0x0a, 0x09, 0x56, 0x4f, 0x49, 0x43, 0x45, 0x4d, 0x41, 0x49, 0x4c, 0x10, 0x04, 0x12, 0x1b, 0x0a,
	0x17, 0x50, 0x52, 0x4f, 0x46, 0x45, 0x53, 0x53, 0x49, 0x4f, 0x4e, 0x41, 0x4c, 0x4c, 0x59, 0x5f,
	0x50, 0x52, 0x4f, 0x44, 0x55, 0x43, 0x45, 0x44, 0x10, 0x05, 0x12, 0x10, 0x0a, 0x0c, 0x56, 0x4f,
	0x49, 0x43, 0x45, 0x5f, 0x53, 0x45, 0x41, 0x52, 0x43, 0x48, 0x10, 0x06, 0x12, 0x11, 0x0a, 0x0d,
	0x56, 0x4f, 0x49, 0x43, 0x45, 0x5f, 0x43, 0x4f, 0x4d, 0x4d, 0x41, 0x4e, 0x44, 0x10, 0x07, 0x12,
	0x0d, 0x0a, 0x09, 0x44, 0x49, 0x43, 0x54, 0x41, 0x54, 0x49, 0x4f, 0x4e, 0x10, 0x08, 0x22, 0x64,
	0x0a, 0x12, 0x4d, 0x69, 0x63, 0x72, 0x6f, 0x70, 0x68, 0x6f, 0x6e, 0x65, 0x44, 0x69, 0x73, 0x74,
	0x61, 0x6e, 0x63, 0x65, 0x12, 0x23, 0x0a, 0x1f, 0x4d, 0x49, 0x43, 0x52, 0x4f, 0x50, 0x48, 0x4f,
	0x4e, 0x45, 0x5f, 0x44, 0x49, 0x53, 0x54, 0x41, 0x4e, 0x43, 0x45, 0x5f, 0x55, 0x4e, 0x53, 0x50,
	0x45, 0x43, 0x49, 0x46, 0x49, 0x45, 0x44, 0x10, 0x00, 0x12, 0x0d, 0x0a, 0x09, 0x4e, 0x45, 0x41,
	0x52, 0x46, 0x49, 0x45, 0x4c, 0x44, 0x10, 0x01, 0x12, 0x0c, 0x0a, 0x08, 0x4d, 0x49, 0x44, 0x46,
	0x49, 0x45, 0x4c, 0x44, 0x10, 0x02, 0x12, 0x0c, 0x0a, 0x08, 0x46, 0x41, 0x52, 0x46, 0x49, 0x45,
	0x4c, 0x44, 0x10, 0x03, 0x22, 0x4e, 0x0a, 0x11, 0x4f, 0x72, 0x69, 0x67, 0x69, 0x6e, 0x61, 0x6c,
	0x4d, 0x65, 0x64, 0x69, 0x61, 0x54, 0x79, 0x70, 0x65, 0x12, 0x23, 0x0a, 0x1f, 0x4f, 0x52, 0x49,
	0x47, 0x49, 0x4e, 0x41, 0x4c, 0x5f, 0x4d, 0x45, 0x44, 0x49, 0x41, 0x5f, 0x54, 0x59, 0x50, 0x45,
	0x5f, 0x55, 0x4e, 0x53, 0x50, 0x45, 0x43, 0x49, 0x46, 0x49, 0x45, 0x44, 0x10, 0x00, 0x12, 0x09,
	0x0a, 0x05, 0x41, 0x55, 0x44, 0x49, 0x4f, 0x10, 0x01, 0x12, 0x09, 0x0a, 0x05, 0x56, 0x49, 0x44,
	0x45, 0x4f, 0x10, 0x02, 0x22, 0xa4, 0x01, 0x0a, 0x13, 0x52, 0x65, 0x63, 0x6f, 0x72, 0x64, 0x69,
	0x6e, 0x67, 0x44, 0x65, 0x76, 0x69, 0x63, 0x65, 0x54, 0x79, 0x70, 0x65, 0x12, 0x25, 0x0a, 0x21,
	0x52, 0x45, 0x43, 0x4f, 0x52, 0x44, 0x49, 0x4e, 0x47, 0x5f, 0x44, 0x45, 0x56, 0x49, 0x43, 0x45,
	0x5f, 0x54, 0x59, 0x50, 0x45, 0x5f, 0x55, 0x4e, 0x53, 0x50, 0x45, 0x43, 0x49, 0x46, 0x49, 0x45,
	0x44, 0x10, 0x00, 0x12, 0x0e, 0x0a, 0x0a, 0x53, 0x4d, 0x41, 0x52, 0x54, 0x50, 0x48, 0x4f, 0x4e,
	0x45, 0x10, 0x01, 0x12, 0x06, 0x0a, 0x02, 0x50, 0x43, 0x10, 0x02, 0x12, 0x0e, 0x0a, 0x0a, 0x50,
	0x48, 0x4f, 0x4e, 0x45, 0x5f, 0x4c, 0x49, 0x4e, 0x45, 0x10, 0x03, 0x12, 0x0b, 0x0a, 0x07, 0x56,
	0x45, 0x48, 0x49, 0x43, 0x4c, 0x45, 0x10, 0x04, 0x12, 0x18, 0x0a, 0x14, 0x4f, 0x54, 0x48, 0x45,
	0x52, 0x5f, 0x4f, 0x55, 0x54, 0x44, 0x4f, 0x4f, 0x52, 0x5f, 0x44, 0x45, 0x56, 0x49, 0x43, 0x45,
	0x10, 0x05, 0x12, 0x17, 0x0a, 0x13, 0x4f, 0x54, 0x48, 0x45, 0x52, 0x5f, 0x49, 0x4e, 0x44, 0x4f,
	0x4f, 0x52, 0x5f, 0x44, 0x45, 0x56, 0x49, 0x43, 0x45, 0x10, 0x06, 0x22, 0x29, 0x0a, 0x0d, 0x53,
	0x70, 0x65, 0x65, 0x63, 0x68, 0x43, 0x6f, 0x6e, 0x74, 0x65, 0x78, 0x74, 0x12, 0x18, 0x0a, 0x07,
	0x70, 0x68, 0x72, 0x61, 0x73, 0x65, 0x73, 0x18, 0x01, 0x20, 0x03, 0x28, 0x09, 0x52, 0x07, 0x70,
	0x68, 0x72, 0x61, 0x73, 0x65, 0x73, 0x22, 0x52, 0x0a, 0x10, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e,
	0x69, 0x74, 0x69, 0x6f, 0x6e, 0x41, 0x75, 0x64, 0x69, 0x6f, 0x12, 0x1a, 0x0a, 0x07, 0x63, 0x6f,
	0x6e, 0x74, 0x65, 0x6e, 0x74, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0c, 0x48, 0x00, 0x52, 0x07, 0x63,
	0x6f, 0x6e, 0x74, 0x65, 0x6e, 0x74, 0x12, 0x12, 0x0a, 0x03, 0x75, 0x72, 0x69, 0x18, 0x02, 0x20,
	0x01, 0x28, 0x09, 0x48, 0x00, 0x52, 0x03, 0x75, 0x72, 0x69, 0x42, 0x0e, 0x0a, 0x0c, 0x61, 0x75,
	0x64, 0x69, 0x6f, 0x5f, 0x73, 0x6f, 0x75, 0x72, 0x63, 0x65, 0x22, 0x5e, 0x0a, 0x11, 0x52, 0x65,
	0x63, 0x6f, 0x67, 0x6e, 0x69, 0x7a, 0x65, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x12,
	0x49, 0x0a, 0x07, 0x72, 0x65, 0x73, 0x75, 0x6c, 0x74, 0x73, 0x18, 0x02, 0x20, 0x03, 0x28, 0x0b,
	0x32, 0x2f, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e,
	0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x53, 0x70, 0x65, 0x65, 0x63, 0x68,
	0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x52, 0x65, 0x73, 0x75, 0x6c,
	0x74, 0x52, 0x07, 0x72, 0x65, 0x73, 0x75, 0x6c, 0x74, 0x73, 0x22, 0x69, 0x0a, 0x1c, 0x4c, 0x6f,
	0x6e, 0x67, 0x52, 0x75, 0x6e, 0x6e, 0x69, 0x6e, 0x67, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69,
	0x7a, 0x65, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x12, 0x49, 0x0a, 0x07, 0x72, 0x65,
	0x73, 0x75, 0x6c, 0x74, 0x73, 0x18, 0x02, 0x20, 0x03, 0x28, 0x0b, 0x32, 0x2f, 0x2e, 0x67, 0x6f,
	0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65, 0x63,
	0x68, 0x2e, 0x76, 0x31, 0x2e, 0x53, 0x70, 0x65, 0x65, 0x63, 0x68, 0x52, 0x65, 0x63, 0x6f, 0x67,
	0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x52, 0x65, 0x73, 0x75, 0x6c, 0x74, 0x52, 0x07, 0x72, 0x65,
	0x73, 0x75, 0x6c, 0x74, 0x73, 0x22, 0xca, 0x01, 0x0a, 0x1c, 0x4c, 0x6f, 0x6e, 0x67, 0x52, 0x75,
	0x6e, 0x6e, 0x69, 0x6e, 0x67, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x7a, 0x65, 0x4d, 0x65,
	0x74, 0x61, 0x64, 0x61, 0x74, 0x61, 0x12, 0x29, 0x0a, 0x10, 0x70, 0x72, 0x6f, 0x67, 0x72, 0x65,
	0x73, 0x73, 0x5f, 0x70, 0x65, 0x72, 0x63, 0x65, 0x6e, 0x74, 0x18, 0x01, 0x20, 0x01, 0x28, 0x05,
	0x52, 0x0f, 0x70, 0x72, 0x6f, 0x67, 0x72, 0x65, 0x73, 0x73, 0x50, 0x65, 0x72, 0x63, 0x65, 0x6e,
	0x74, 0x12, 0x39, 0x0a, 0x0a, 0x73, 0x74, 0x61, 0x72, 0x74, 0x5f, 0x74, 0x69, 0x6d, 0x65, 0x18,
	0x02, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x1a, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x70,
	0x72, 0x6f, 0x74, 0x6f, 0x62, 0x75, 0x66, 0x2e, 0x54, 0x69, 0x6d, 0x65, 0x73, 0x74, 0x61, 0x6d,
	0x70, 0x52, 0x09, 0x73, 0x74, 0x61, 0x72, 0x74, 0x54, 0x69, 0x6d, 0x65, 0x12, 0x44, 0x0a, 0x10,
	0x6c, 0x61, 0x73, 0x74, 0x5f, 0x75, 0x70, 0x64, 0x61, 0x74, 0x65, 0x5f, 0x74, 0x69, 0x6d, 0x65,
	0x18, 0x03, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x1a, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e,
	0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62, 0x75, 0x66, 0x2e, 0x54, 0x69, 0x6d, 0x65, 0x73, 0x74, 0x61,
	0x6d, 0x70, 0x52, 0x0e, 0x6c, 0x61, 0x73, 0x74, 0x55, 0x70, 0x64, 0x61, 0x74, 0x65, 0x54, 0x69,
	0x6d, 0x65, 0x22, 0xd2, 0x02, 0x0a, 0x1a, 0x53, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x69, 0x6e, 0x67,
	0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x7a, 0x65, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73,
	0x65, 0x12, 0x28, 0x0a, 0x05, 0x65, 0x72, 0x72, 0x6f, 0x72, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0b,
	0x32, 0x12, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x72, 0x70, 0x63, 0x2e, 0x53, 0x74,
	0x61, 0x74, 0x75, 0x73, 0x52, 0x05, 0x65, 0x72, 0x72, 0x6f, 0x72, 0x12, 0x4c, 0x0a, 0x07, 0x72,
	0x65, 0x73, 0x75, 0x6c, 0x74, 0x73, 0x18, 0x02, 0x20, 0x03, 0x28, 0x0b, 0x32, 0x32, 0x2e, 0x67,
	0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65,
	0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x53, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x69, 0x6e, 0x67, 0x52,
	0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x52, 0x65, 0x73, 0x75, 0x6c, 0x74,
	0x52, 0x07, 0x72, 0x65, 0x73, 0x75, 0x6c, 0x74, 0x73, 0x12, 0x6e, 0x0a, 0x11, 0x73, 0x70, 0x65,
	0x65, 0x63, 0x68, 0x5f, 0x65, 0x76, 0x65, 0x6e, 0x74, 0x5f, 0x74, 0x79, 0x70, 0x65, 0x18, 0x04,
	0x20, 0x01, 0x28, 0x0e, 0x32, 0x42, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c,
	0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x53, 0x74,
	0x72, 0x65, 0x61, 0x6d, 0x69, 0x6e, 0x67, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x7a, 0x65,
	0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x2e, 0x53, 0x70, 0x65, 0x65, 0x63, 0x68, 0x45,
	0x76, 0x65, 0x6e, 0x74, 0x54, 0x79, 0x70, 0x65, 0x52, 0x0f, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68,
	0x45, 0x76, 0x65, 0x6e, 0x74, 0x54, 0x79, 0x70, 0x65, 0x22, 0x4c, 0x0a, 0x0f, 0x53, 0x70, 0x65,
	0x65, 0x63, 0x68, 0x45, 0x76, 0x65, 0x6e, 0x74, 0x54, 0x79, 0x70, 0x65, 0x12, 0x1c, 0x0a, 0x18,
	0x53, 0x50, 0x45, 0x45, 0x43, 0x48, 0x5f, 0x45, 0x56, 0x45, 0x4e, 0x54, 0x5f, 0x55, 0x4e, 0x53,
	0x50, 0x45, 0x43, 0x49, 0x46, 0x49, 0x45, 0x44, 0x10, 0x00, 0x12, 0x1b, 0x0a, 0x17, 0x45, 0x4e,
	0x44, 0x5f, 0x4f, 0x46, 0x5f, 0x53, 0x49, 0x4e, 0x47, 0x4c, 0x45, 0x5f, 0x55, 0x54, 0x54, 0x45,
	0x52, 0x41, 0x4e, 0x43, 0x45, 0x10, 0x01, 0x22, 0xbd, 0x02, 0x0a, 0x1a, 0x53, 0x74, 0x72, 0x65,
	0x61, 0x6d, 0x69, 0x6e, 0x67, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e,
	0x52, 0x65, 0x73, 0x75, 0x6c, 0x74, 0x12, 0x58, 0x0a, 0x0c, 0x61, 0x6c, 0x74, 0x65, 0x72, 0x6e,
	0x61, 0x74, 0x69, 0x76, 0x65, 0x73, 0x18, 0x01, 0x20, 0x03, 0x28, 0x0b, 0x32, 0x34, 0x2e, 0x67,
	0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65,
	0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x53, 0x70, 0x65, 0x65, 0x63, 0x68, 0x52, 0x65, 0x63, 0x6f,
	0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x41, 0x6c, 0x74, 0x65, 0x72, 0x6e, 0x61, 0x74, 0x69,
	0x76, 0x65, 0x52, 0x0c, 0x61, 0x6c, 0x74, 0x65, 0x72, 0x6e, 0x61, 0x74, 0x69, 0x76, 0x65, 0x73,
	0x12, 0x19, 0x0a, 0x08, 0x69, 0x73, 0x5f, 0x66, 0x69, 0x6e, 0x61, 0x6c, 0x18, 0x02, 0x20, 0x01,
	0x28, 0x08, 0x52, 0x07, 0x69, 0x73, 0x46, 0x69, 0x6e, 0x61, 0x6c, 0x12, 0x1c, 0x0a, 0x09, 0x73,
	0x74, 0x61, 0x62, 0x69, 0x6c, 0x69, 0x74, 0x79, 0x18, 0x03, 0x20, 0x01, 0x28, 0x02, 0x52, 0x09,
	0x73, 0x74, 0x61, 0x62, 0x69, 0x6c, 0x69, 0x74, 0x79, 0x12, 0x41, 0x0a, 0x0f, 0x72, 0x65, 0x73,
	0x75, 0x6c, 0x74, 0x5f, 0x65, 0x6e, 0x64, 0x5f, 0x74, 0x69, 0x6d, 0x65, 0x18, 0x04, 0x20, 0x01,
	0x28, 0x0b, 0x32, 0x19, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x70, 0x72, 0x6f, 0x74,
	0x6f, 0x62, 0x75, 0x66, 0x2e, 0x44, 0x75, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x52, 0x0d, 0x72,
	0x65, 0x73, 0x75, 0x6c, 0x74, 0x45, 0x6e, 0x64, 0x54, 0x69, 0x6d, 0x65, 0x12, 0x1f, 0x0a, 0x0b,
	0x63, 0x68, 0x61, 0x6e, 0x6e, 0x65, 0x6c, 0x5f, 0x74, 0x61, 0x67, 0x18, 0x05, 0x20, 0x01, 0x28,
	0x05, 0x52, 0x0a, 0x63, 0x68, 0x61, 0x6e, 0x6e, 0x65, 0x6c, 0x54, 0x61, 0x67, 0x12, 0x28, 0x0a,
	0x0d, 0x6c, 0x61, 0x6e, 0x67, 0x75, 0x61, 0x67, 0x65, 0x5f, 0x63, 0x6f, 0x64, 0x65, 0x18, 0x06,
	0x20, 0x01, 0x28, 0x09, 0x42, 0x03, 0xe0, 0x41, 0x03, 0x52, 0x0c, 0x6c, 0x61, 0x6e, 0x67, 0x75,
	0x61, 0x67, 0x65, 0x43, 0x6f, 0x64, 0x65, 0x22, 0x94, 0x01, 0x0a, 0x17, 0x53, 0x70, 0x65, 0x65,
	0x63, 0x68, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x52, 0x65, 0x73,
	0x75, 0x6c, 0x74, 0x12, 0x58, 0x0a, 0x0c, 0x61, 0x6c, 0x74, 0x65, 0x72, 0x6e, 0x61, 0x74, 0x69,
	0x76, 0x65, 0x73, 0x18, 0x01, 0x20, 0x03, 0x28, 0x0b, 0x32, 0x34, 0x2e, 0x67, 0x6f, 0x6f, 0x67,
	0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x2e,
	0x76, 0x31, 0x2e, 0x53, 0x70, 0x65, 0x65, 0x63, 0x68, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69,
	0x74, 0x69, 0x6f, 0x6e, 0x41, 0x6c, 0x74, 0x65, 0x72, 0x6e, 0x61, 0x74, 0x69, 0x76, 0x65, 0x52,
	0x0c, 0x61, 0x6c, 0x74, 0x65, 0x72, 0x6e, 0x61, 0x74, 0x69, 0x76, 0x65, 0x73, 0x12, 0x1f, 0x0a,
	0x0b, 0x63, 0x68, 0x61, 0x6e, 0x6e, 0x65, 0x6c, 0x5f, 0x74, 0x61, 0x67, 0x18, 0x02, 0x20, 0x01,
	0x28, 0x05, 0x52, 0x0a, 0x63, 0x68, 0x61, 0x6e, 0x6e, 0x65, 0x6c, 0x54, 0x61, 0x67, 0x22, 0x96,
	0x01, 0x0a, 0x1c, 0x53, 0x70, 0x65, 0x65, 0x63, 0x68, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69,
	0x74, 0x69, 0x6f, 0x6e, 0x41, 0x6c, 0x74, 0x65, 0x72, 0x6e, 0x61, 0x74, 0x69, 0x76, 0x65, 0x12,
	0x1e, 0x0a, 0x0a, 0x74, 0x72, 0x61, 0x6e, 0x73, 0x63, 0x72, 0x69, 0x70, 0x74, 0x18, 0x01, 0x20,
	0x01, 0x28, 0x09, 0x52, 0x0a, 0x74, 0x72, 0x61, 0x6e, 0x73, 0x63, 0x72, 0x69, 0x70, 0x74, 0x12,
	0x1e, 0x0a, 0x0a, 0x63, 0x6f, 0x6e, 0x66, 0x69, 0x64, 0x65, 0x6e, 0x63, 0x65, 0x18, 0x02, 0x20,
	0x01, 0x28, 0x02, 0x52, 0x0a, 0x63, 0x6f, 0x6e, 0x66, 0x69, 0x64, 0x65, 0x6e, 0x63, 0x65, 0x12,
	0x36, 0x0a, 0x05, 0x77, 0x6f, 0x72, 0x64, 0x73, 0x18, 0x03, 0x20, 0x03, 0x28, 0x0b, 0x32, 0x20,
	0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70,
	0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x57, 0x6f, 0x72, 0x64, 0x49, 0x6e, 0x66, 0x6f,
	0x52, 0x05, 0x77, 0x6f, 0x72, 0x64, 0x73, 0x22, 0xb4, 0x01, 0x0a, 0x08, 0x57, 0x6f, 0x72, 0x64,
	0x49, 0x6e, 0x66, 0x6f, 0x12, 0x38, 0x0a, 0x0a, 0x73, 0x74, 0x61, 0x72, 0x74, 0x5f, 0x74, 0x69,
	0x6d, 0x65, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x19, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c,
	0x65, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62, 0x75, 0x66, 0x2e, 0x44, 0x75, 0x72, 0x61, 0x74,
	0x69, 0x6f, 0x6e, 0x52, 0x09, 0x73, 0x74, 0x61, 0x72, 0x74, 0x54, 0x69, 0x6d, 0x65, 0x12, 0x34,
	0x0a, 0x08, 0x65, 0x6e, 0x64, 0x5f, 0x74, 0x69, 0x6d, 0x65, 0x18, 0x02, 0x20, 0x01, 0x28, 0x0b,
	0x32, 0x19, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62,
	0x75, 0x66, 0x2e, 0x44, 0x75, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x52, 0x07, 0x65, 0x6e, 0x64,
	0x54, 0x69, 0x6d, 0x65, 0x12, 0x12, 0x0a, 0x04, 0x77, 0x6f, 0x72, 0x64, 0x18, 0x03, 0x20, 0x01,
	0x28, 0x09, 0x52, 0x04, 0x77, 0x6f, 0x72, 0x64, 0x12, 0x24, 0x0a, 0x0b, 0x73, 0x70, 0x65, 0x61,
	0x6b, 0x65, 0x72, 0x5f, 0x74, 0x61, 0x67, 0x18, 0x05, 0x20, 0x01, 0x28, 0x05, 0x42, 0x03, 0xe0,
	0x41, 0x03, 0x52, 0x0a, 0x73, 0x70, 0x65, 0x61, 0x6b, 0x65, 0x72, 0x54, 0x61, 0x67, 0x32, 0xd1,
	0x04, 0x0a, 0x06, 0x53, 0x70, 0x65, 0x65, 0x63, 0x68, 0x12, 0x90, 0x01, 0x0a, 0x09, 0x52, 0x65,
	0x63, 0x6f, 0x67, 0x6e, 0x69, 0x7a, 0x65, 0x12, 0x28, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65,
	0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31,
	0x2e, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x7a, 0x65, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73,
	0x74, 0x1a, 0x29, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64,
	0x2e, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x52, 0x65, 0x63, 0x6f, 0x67,
	0x6e, 0x69, 0x7a, 0x65, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x22, 0x2e, 0x82, 0xd3,
	0xe4, 0x93, 0x02, 0x19, 0x22, 0x14, 0x2f, 0x76, 0x31, 0x2f, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68,
	0x3a, 0x72, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x7a, 0x65, 0x3a, 0x01, 0x2a, 0xda, 0x41, 0x0c,
	0x63, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x2c, 0x61, 0x75, 0x64, 0x69, 0x6f, 0x12, 0xe4, 0x01, 0x0a,
	0x14, 0x4c, 0x6f, 0x6e, 0x67, 0x52, 0x75, 0x6e, 0x6e, 0x69, 0x6e, 0x67, 0x52, 0x65, 0x63, 0x6f,
	0x67, 0x6e, 0x69, 0x7a, 0x65, 0x12, 0x33, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63,
	0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x4c,
	0x6f, 0x6e, 0x67, 0x52, 0x75, 0x6e, 0x6e, 0x69, 0x6e, 0x67, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e,
	0x69, 0x7a, 0x65, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x1a, 0x1d, 0x2e, 0x67, 0x6f, 0x6f,
	0x67, 0x6c, 0x65, 0x2e, 0x6c, 0x6f, 0x6e, 0x67, 0x72, 0x75, 0x6e, 0x6e, 0x69, 0x6e, 0x67, 0x2e,
	0x4f, 0x70, 0x65, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x22, 0x78, 0x82, 0xd3, 0xe4, 0x93, 0x02,
	0x24, 0x22, 0x1f, 0x2f, 0x76, 0x31, 0x2f, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x3a, 0x6c, 0x6f,
	0x6e, 0x67, 0x72, 0x75, 0x6e, 0x6e, 0x69, 0x6e, 0x67, 0x72, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69,
	0x7a, 0x65, 0x3a, 0x01, 0x2a, 0xda, 0x41, 0x0c, 0x63, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x2c, 0x61,
	0x75, 0x64, 0x69, 0x6f, 0xca, 0x41, 0x3c, 0x0a, 0x1c, 0x4c, 0x6f, 0x6e, 0x67, 0x52, 0x75, 0x6e,
	0x6e, 0x69, 0x6e, 0x67, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x7a, 0x65, 0x52, 0x65, 0x73,
	0x70, 0x6f, 0x6e, 0x73, 0x65, 0x12, 0x1c, 0x4c, 0x6f, 0x6e, 0x67, 0x52, 0x75, 0x6e, 0x6e, 0x69,
	0x6e, 0x67, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x7a, 0x65, 0x4d, 0x65, 0x74, 0x61, 0x64,
	0x61, 0x74, 0x61, 0x12, 0x81, 0x01, 0x0a, 0x12, 0x53, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x69, 0x6e,
	0x67, 0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x7a, 0x65, 0x12, 0x31, 0x2e, 0x67, 0x6f, 0x6f,
	0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68,
	0x2e, 0x76, 0x31, 0x2e, 0x53, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x69, 0x6e, 0x67, 0x52, 0x65, 0x63,
	0x6f, 0x67, 0x6e, 0x69, 0x7a, 0x65, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x1a, 0x32, 0x2e,
	0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65,
	0x65, 0x63, 0x68, 0x2e, 0x76, 0x31, 0x2e, 0x53, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x69, 0x6e, 0x67,
	0x52, 0x65, 0x63, 0x6f, 0x67, 0x6e, 0x69, 0x7a, 0x65, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73,
	0x65, 0x22, 0x00, 0x28, 0x01, 0x30, 0x01, 0x1a, 0x49, 0xca, 0x41, 0x15, 0x73, 0x70, 0x65, 0x65,
	0x63, 0x68, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x61, 0x70, 0x69, 0x73, 0x2e, 0x63, 0x6f,
	0x6d, 0xd2, 0x41, 0x2e, 0x68, 0x74, 0x74, 0x70, 0x73, 0x3a, 0x2f, 0x2f, 0x77, 0x77, 0x77, 0x2e,
	0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x61, 0x70, 0x69, 0x73, 0x2e, 0x63, 0x6f, 0x6d, 0x2f, 0x61,
	0x75, 0x74, 0x68, 0x2f, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2d, 0x70, 0x6c, 0x61, 0x74, 0x66, 0x6f,
	0x72, 0x6d, 0x42, 0x72, 0x0a, 0x1a, 0x63, 0x6f, 0x6d, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65,
	0x2e, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2e, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0x2e, 0x76, 0x31,
	0x42, 0x0b, 0x53, 0x70, 0x65, 0x65, 0x63, 0x68, 0x50, 0x72, 0x6f, 0x74, 0x6f, 0x50, 0x01, 0x5a,
	0x3c, 0x67, 0x6f, 0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x67, 0x6f, 0x6c, 0x61, 0x6e, 0x67, 0x2e, 0x6f,
	0x72, 0x67, 0x2f, 0x67, 0x65, 0x6e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2f, 0x67, 0x6f, 0x6f, 0x67,
	0x6c, 0x65, 0x61, 0x70, 0x69, 0x73, 0x2f, 0x63, 0x6c, 0x6f, 0x75, 0x64, 0x2f, 0x73, 0x70, 0x65,
	0x65, 0x63, 0x68, 0x2f, 0x76, 0x31, 0x3b, 0x73, 0x70, 0x65, 0x65, 0x63, 0x68, 0xf8, 0x01, 0x01,
	0xa2, 0x02, 0x03, 0x47, 0x43, 0x53, 0x62, 0x06, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x33,
}

var (
	file_google_cloud_speech_v1_cloud_speech_proto_rawDescOnce sync.Once
	file_google_cloud_speech_v1_cloud_speech_proto_rawDescData = file_google_cloud_speech_v1_cloud_speech_proto_rawDesc
)

func file_google_cloud_speech_v1_cloud_speech_proto_rawDescGZIP() []byte {
	file_google_cloud_speech_v1_cloud_speech_proto_rawDescOnce.Do(func() {
		file_google_cloud_speech_v1_cloud_speech_proto_rawDescData = protoimpl.X.CompressGZIP(file_google_cloud_speech_v1_cloud_speech_proto_rawDescData)
	})
	return file_google_cloud_speech_v1_cloud_speech_proto_rawDescData
}

var file_google_cloud_speech_v1_cloud_speech_proto_enumTypes = make([]protoimpl.EnumInfo, 6)
var file_google_cloud_speech_v1_cloud_speech_proto_msgTypes = make([]protoimpl.MessageInfo, 17)
var file_google_cloud_speech_v1_cloud_speech_proto_goTypes = []interface{}{
	(RecognitionConfig_AudioEncoding)(0),            // 0: google.cloud.speech.v1.RecognitionConfig.AudioEncoding
	(RecognitionMetadata_InteractionType)(0),        // 1: google.cloud.speech.v1.RecognitionMetadata.InteractionType
	(RecognitionMetadata_MicrophoneDistance)(0),     // 2: google.cloud.speech.v1.RecognitionMetadata.MicrophoneDistance
	(RecognitionMetadata_OriginalMediaType)(0),      // 3: google.cloud.speech.v1.RecognitionMetadata.OriginalMediaType
	(RecognitionMetadata_RecordingDeviceType)(0),    // 4: google.cloud.speech.v1.RecognitionMetadata.RecordingDeviceType
	(StreamingRecognizeResponse_SpeechEventType)(0), // 5: google.cloud.speech.v1.StreamingRecognizeResponse.SpeechEventType
	(*RecognizeRequest)(nil),                        // 6: google.cloud.speech.v1.RecognizeRequest
	(*LongRunningRecognizeRequest)(nil),             // 7: google.cloud.speech.v1.LongRunningRecognizeRequest
	(*StreamingRecognizeRequest)(nil),               // 8: google.cloud.speech.v1.StreamingRecognizeRequest
	(*StreamingRecognitionConfig)(nil),              // 9: google.cloud.speech.v1.StreamingRecognitionConfig
	(*RecognitionConfig)(nil),                       // 10: google.cloud.speech.v1.RecognitionConfig
	(*SpeakerDiarizationConfig)(nil),                // 11: google.cloud.speech.v1.SpeakerDiarizationConfig
	(*RecognitionMetadata)(nil),                     // 12: google.cloud.speech.v1.RecognitionMetadata
	(*SpeechContext)(nil),                           // 13: google.cloud.speech.v1.SpeechContext
	(*RecognitionAudio)(nil),                        // 14: google.cloud.speech.v1.RecognitionAudio
	(*RecognizeResponse)(nil),                       // 15: google.cloud.speech.v1.RecognizeResponse
	(*LongRunningRecognizeResponse)(nil),            // 16: google.cloud.speech.v1.LongRunningRecognizeResponse
	(*LongRunningRecognizeMetadata)(nil),            // 17: google.cloud.speech.v1.LongRunningRecognizeMetadata
	(*StreamingRecognizeResponse)(nil),              // 18: google.cloud.speech.v1.StreamingRecognizeResponse
	(*StreamingRecognitionResult)(nil),              // 19: google.cloud.speech.v1.StreamingRecognitionResult
	(*SpeechRecognitionResult)(nil),                 // 20: google.cloud.speech.v1.SpeechRecognitionResult
	(*SpeechRecognitionAlternative)(nil),            // 21: google.cloud.speech.v1.SpeechRecognitionAlternative
	(*WordInfo)(nil),                                // 22: google.cloud.speech.v1.WordInfo
	(*timestamppb.Timestamp)(nil),                   // 23: google.protobuf.Timestamp
	(*status.Status)(nil),                           // 24: google.rpc.Status
	(*durationpb.Duration)(nil),                     // 25: google.protobuf.Duration
	(*longrunning.Operation)(nil),                   // 26: google.longrunning.Operation
}
var file_google_cloud_speech_v1_cloud_speech_proto_depIdxs = []int32{
	10, // 0: google.cloud.speech.v1.RecognizeRequest.config:type_name -> google.cloud.speech.v1.RecognitionConfig
	14, // 1: google.cloud.speech.v1.RecognizeRequest.audio:type_name -> google.cloud.speech.v1.RecognitionAudio
	10, // 2: google.cloud.speech.v1.LongRunningRecognizeRequest.config:type_name -> google.cloud.speech.v1.RecognitionConfig
	14, // 3: google.cloud.speech.v1.LongRunningRecognizeRequest.audio:type_name -> google.cloud.speech.v1.RecognitionAudio
	9,  // 4: google.cloud.speech.v1.StreamingRecognizeRequest.streaming_config:type_name -> google.cloud.speech.v1.StreamingRecognitionConfig
	10, // 5: google.cloud.speech.v1.StreamingRecognitionConfig.config:type_name -> google.cloud.speech.v1.RecognitionConfig
	0,  // 6: google.cloud.speech.v1.RecognitionConfig.encoding:type_name -> google.cloud.speech.v1.RecognitionConfig.AudioEncoding
	13, // 7: google.cloud.speech.v1.RecognitionConfig.speech_contexts:type_name -> google.cloud.speech.v1.SpeechContext
	11, // 8: google.cloud.speech.v1.RecognitionConfig.diarization_config:type_name -> google.cloud.speech.v1.SpeakerDiarizationConfig
	12, // 9: google.cloud.speech.v1.RecognitionConfig.metadata:type_name -> google.cloud.speech.v1.RecognitionMetadata
	1,  // 10: google.cloud.speech.v1.RecognitionMetadata.interaction_type:type_name -> google.cloud.speech.v1.RecognitionMetadata.InteractionType
	2,  // 11: google.cloud.speech.v1.RecognitionMetadata.microphone_distance:type_name -> google.cloud.speech.v1.RecognitionMetadata.MicrophoneDistance
	3,  // 12: google.cloud.speech.v1.RecognitionMetadata.original_media_type:type_name -> google.cloud.speech.v1.RecognitionMetadata.OriginalMediaType
	4,  // 13: google.cloud.speech.v1.RecognitionMetadata.recording_device_type:type_name -> google.cloud.speech.v1.RecognitionMetadata.RecordingDeviceType
	20, // 14: google.cloud.speech.v1.RecognizeResponse.results:type_name -> google.cloud.speech.v1.SpeechRecognitionResult
	20, // 15: google.cloud.speech.v1.LongRunningRecognizeResponse.results:type_name -> google.cloud.speech.v1.SpeechRecognitionResult
	23, // 16: google.cloud.speech.v1.LongRunningRecognizeMetadata.start_time:type_name -> google.protobuf.Timestamp
	23, // 17: google.cloud.speech.v1.LongRunningRecognizeMetadata.last_update_time:type_name -> google.protobuf.Timestamp
	24, // 18: google.cloud.speech.v1.StreamingRecognizeResponse.error:type_name -> google.rpc.Status
	19, // 19: google.cloud.speech.v1.StreamingRecognizeResponse.results:type_name -> google.cloud.speech.v1.StreamingRecognitionResult
	5,  // 20: google.cloud.speech.v1.StreamingRecognizeResponse.speech_event_type:type_name -> google.cloud.speech.v1.StreamingRecognizeResponse.SpeechEventType
	21, // 21: google.cloud.speech.v1.StreamingRecognitionResult.alternatives:type_name -> google.cloud.speech.v1.SpeechRecognitionAlternative
	25, // 22: google.cloud.speech.v1.StreamingRecognitionResult.result_end_time:type_name -> google.protobuf.Duration
	21, // 23: google.cloud.speech.v1.SpeechRecognitionResult.alternatives:type_name -> google.cloud.speech.v1.SpeechRecognitionAlternative
	22, // 24: google.cloud.speech.v1.SpeechRecognitionAlternative.words:type_name -> google.cloud.speech.v1.WordInfo
	25, // 25: google.cloud.speech.v1.WordInfo.start_time:type_name -> google.protobuf.Duration
	25, // 26: google.cloud.speech.v1.WordInfo.end_time:type_name -> google.protobuf.Duration
	6,  // 27: google.cloud.speech.v1.Speech.Recognize:input_type -> google.cloud.speech.v1.RecognizeRequest
	7,  // 28: google.cloud.speech.v1.Speech.LongRunningRecognize:input_type -> google.cloud.speech.v1.LongRunningRecognizeRequest
	8,  // 29: google.cloud.speech.v1.Speech.StreamingRecognize:input_type -> google.cloud.speech.v1.StreamingRecognizeRequest
	15, // 30: google.cloud.speech.v1.Speech.Recognize:output_type -> google.cloud.speech.v1.RecognizeResponse
	26, // 31: google.cloud.speech.v1.Speech.LongRunningRecognize:output_type -> google.longrunning.Operation
	18, // 32: google.cloud.speech.v1.Speech.StreamingRecognize:output_type -> google.cloud.speech.v1.StreamingRecognizeResponse
	30, // [30:33] is the sub-list for method output_type
	27, // [27:30] is the sub-list for method input_type
	27, // [27:27] is the sub-list for extension type_name
	27, // [27:27] is the sub-list for extension extendee
	0,  // [0:27] is the sub-list for field type_name
}

func init() { file_google_cloud_speech_v1_cloud_speech_proto_init() }
func file_google_cloud_speech_v1_cloud_speech_proto_init() {
	if File_google_cloud_speech_v1_cloud_speech_proto != nil {
		return
	}
	if !protoimpl.UnsafeEnabled {
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[0].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*RecognizeRequest); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[1].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*LongRunningRecognizeRequest); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[2].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*StreamingRecognizeRequest); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[3].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*StreamingRecognitionConfig); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[4].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*RecognitionConfig); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[5].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*SpeakerDiarizationConfig); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[6].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*RecognitionMetadata); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[7].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*SpeechContext); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[8].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*RecognitionAudio); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[9].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*RecognizeResponse); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[10].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*LongRunningRecognizeResponse); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[11].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*LongRunningRecognizeMetadata); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[12].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*StreamingRecognizeResponse); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[13].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*StreamingRecognitionResult); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[14].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*SpeechRecognitionResult); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[15].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*SpeechRecognitionAlternative); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[16].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*WordInfo); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
	}
	file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[2].OneofWrappers = []interface{}{
		(*StreamingRecognizeRequest_StreamingConfig)(nil),
		(*StreamingRecognizeRequest_AudioContent)(nil),
	}
	file_google_cloud_speech_v1_cloud_speech_proto_msgTypes[8].OneofWrappers = []interface{}{
		(*RecognitionAudio_Content)(nil),
		(*RecognitionAudio_Uri)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: file_google_cloud_speech_v1_cloud_speech_proto_rawDesc,
			NumEnums:      6,
			NumMessages:   17,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_google_cloud_speech_v1_cloud_speech_proto_goTypes,
		DependencyIndexes: file_google_cloud_speech_v1_cloud_speech_proto_depIdxs,
		EnumInfos:         file_google_cloud_speech_v1_cloud_speech_proto_enumTypes,
		MessageInfos:      file_google_cloud_speech_v1_cloud_speech_proto_msgTypes,
	}.Build()
	File_google_cloud_speech_v1_cloud_speech_proto = out.File
	file_google_cloud_speech_v1_cloud_speech_proto_rawDesc = nil
	file_google_cloud_speech_v1_cloud_speech_proto_goTypes = nil
	file_google_cloud_speech_v1_cloud_speech_proto_depIdxs = nil
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConnInterface

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion6

// SpeechClient is the client API for Speech service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type SpeechClient interface {
	// Performs synchronous speech recognition: receive results after all audio
	// has been sent and processed.
	Recognize(ctx context.Context, in *RecognizeRequest, opts ...grpc.CallOption) (*RecognizeResponse, error)
	// Performs asynchronous speech recognition: receive results via the
	// google.longrunning.Operations interface. Returns either an
	// `Operation.error` or an `Operation.response` which contains
	// a `LongRunningRecognizeResponse` message.
	// For more information on asynchronous speech recognition, see the
	// [how-to](https://cloud.google.com/speech-to-text/docs/async-recognize).
	LongRunningRecognize(ctx context.Context, in *LongRunningRecognizeRequest, opts ...grpc.CallOption) (*longrunning.Operation, error)
	// Performs bidirectional streaming speech recognition: receive results while
	// sending audio. This method is only available via the gRPC API (not REST).
	StreamingRecognize(ctx context.Context, opts ...grpc.CallOption) (Speech_StreamingRecognizeClient, error)
}

type speechClient struct {
	cc grpc.ClientConnInterface
}

func NewSpeechClient(cc grpc.ClientConnInterface) SpeechClient {
	return &speechClient{cc}
}

func (c *speechClient) Recognize(ctx context.Context, in *RecognizeRequest, opts ...grpc.CallOption) (*RecognizeResponse, error) {
	out := new(RecognizeResponse)
	err := c.cc.Invoke(ctx, "/google.cloud.speech.v1.Speech/Recognize", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *speechClient) LongRunningRecognize(ctx context.Context, in *LongRunningRecognizeRequest, opts ...grpc.CallOption) (*longrunning.Operation, error) {
	out := new(longrunning.Operation)
	err := c.cc.Invoke(ctx, "/google.cloud.speech.v1.Speech/LongRunningRecognize", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *speechClient) StreamingRecognize(ctx context.Context, opts ...grpc.CallOption) (Speech_StreamingRecognizeClient, error) {
	stream, err := c.cc.NewStream(ctx, &_Speech_serviceDesc.Streams[0], "/google.cloud.speech.v1.Speech/StreamingRecognize", opts...)
	if err != nil {
		return nil, err
	}
	x := &speechStreamingRecognizeClient{stream}
	return x, nil
}

type Speech_StreamingRecognizeClient interface {
	Send(*StreamingRecognizeRequest) error
	Recv() (*StreamingRecognizeResponse, error)
	grpc.ClientStream
}

type speechStreamingRecognizeClient struct {
	grpc.ClientStream
}

func (x *speechStreamingRecognizeClient) Send(m *StreamingRecognizeRequest) error {
	return x.ClientStream.SendMsg(m)
}

func (x *speechStreamingRecognizeClient) Recv() (*StreamingRecognizeResponse, error) {
	m := new(StreamingRecognizeResponse)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

// SpeechServer is the server API for Speech service.
type SpeechServer interface {
	// Performs synchronous speech recognition: receive results after all audio
	// has been sent and processed.
	Recognize(context.Context, *RecognizeRequest) (*RecognizeResponse, error)
	// Performs asynchronous speech recognition: receive results via the
	// google.longrunning.Operations interface. Returns either an
	// `Operation.error` or an `Operation.response` which contains
	// a `LongRunningRecognizeResponse` message.
	// For more information on asynchronous speech recognition, see the
	// [how-to](https://cloud.google.com/speech-to-text/docs/async-recognize).
	LongRunningRecognize(context.Context, *LongRunningRecognizeRequest) (*longrunning.Operation, error)
	// Performs bidirectional streaming speech recognition: receive results while
	// sending audio. This method is only available via the gRPC API (not REST).
	StreamingRecognize(Speech_StreamingRecognizeServer) error
}

// UnimplementedSpeechServer can be embedded to have forward compatible implementations.
type UnimplementedSpeechServer struct {
}

func (*UnimplementedSpeechServer) Recognize(context.Context, *RecognizeRequest) (*RecognizeResponse, error) {
	return nil, status1.Errorf(codes.Unimplemented, "method Recognize not implemented")
}
func (*UnimplementedSpeechServer) LongRunningRecognize(context.Context, *LongRunningRecognizeRequest) (*longrunning.Operation, error) {
	return nil, status1.Errorf(codes.Unimplemented, "method LongRunningRecognize not implemented")
}
func (*UnimplementedSpeechServer) StreamingRecognize(Speech_StreamingRecognizeServer) error {
	return status1.Errorf(codes.Unimplemented, "method StreamingRecognize not implemented")
}

func RegisterSpeechServer(s *grpc.Server, srv SpeechServer) {
	s.RegisterService(&_Speech_serviceDesc, srv)
}

func _Speech_Recognize_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(RecognizeRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(SpeechServer).Recognize(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/google.cloud.speech.v1.Speech/Recognize",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(SpeechServer).Recognize(ctx, req.(*RecognizeRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Speech_LongRunningRecognize_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(LongRunningRecognizeRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(SpeechServer).LongRunningRecognize(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/google.cloud.speech.v1.Speech/LongRunningRecognize",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(SpeechServer).LongRunningRecognize(ctx, req.(*LongRunningRecognizeRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Speech_StreamingRecognize_Handler(srv interface{}, stream grpc.ServerStream) error {
	return srv.(SpeechServer).StreamingRecognize(&speechStreamingRecognizeServer{stream})
}

type Speech_StreamingRecognizeServer interface {
	Send(*StreamingRecognizeResponse) error
	Recv() (*StreamingRecognizeRequest, error)
	grpc.ServerStream
}

type speechStreamingRecognizeServer struct {
	grpc.ServerStream
}

func (x *speechStreamingRecognizeServer) Send(m *StreamingRecognizeResponse) error {
	return x.ServerStream.SendMsg(m)
}

func (x *speechStreamingRecognizeServer) Recv() (*StreamingRecognizeRequest, error) {
	m := new(StreamingRecognizeRequest)
	if err := x.ServerStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

var _Speech_serviceDesc = grpc.ServiceDesc{
	ServiceName: "google.cloud.speech.v1.Speech",
	HandlerType: (*SpeechServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Recognize",
			Handler:    _Speech_Recognize_Handler,
		},
		{
			MethodName: "LongRunningRecognize",
			Handler:    _Speech_LongRunningRecognize_Handler,
		},
	},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "StreamingRecognize",
			Handler:       _Speech_StreamingRecognize_Handler,
			ServerStreams: true,
			ClientStreams: true,
		},
	},
	Metadata: "google/cloud/speech/v1/cloud_speech.proto",
}
