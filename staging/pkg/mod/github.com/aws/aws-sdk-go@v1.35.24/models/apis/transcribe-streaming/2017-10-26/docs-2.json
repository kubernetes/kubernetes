{
  "version": "2.0",
  "service": "<p>Operations and objects for transcribing streaming speech to text.</p>",
  "operations": {
    "StartStreamTranscription": "<p>Starts a bidirectional HTTP2 stream where audio is streamed to Amazon Transcribe and the transcription results are streamed to your application.</p> <p>The following are encoded as HTTP2 headers:</p> <ul> <li> <p>x-amzn-transcribe-language-code</p> </li> <li> <p>x-amzn-transcribe-media-encoding</p> </li> <li> <p>x-amzn-transcribe-sample-rate</p> </li> <li> <p>x-amzn-transcribe-session-id</p> </li> </ul>"
  },
  "shapes": {
    "Alternative": {
      "base": "<p>A list of possible transcriptions for the audio.</p>",
      "refs": {
        "AlternativeList$member": null
      }
    },
    "AlternativeList": {
      "base": null,
      "refs": {
        "Result$Alternatives": "<p>A list of possible transcriptions for the audio. Each alternative typically contains one <code>item</code> that contains the result of the transcription.</p>"
      }
    },
    "AudioChunk": {
      "base": null,
      "refs": {
        "AudioEvent$AudioChunk": "<p>An audio blob that contains the next part of the audio that you want to transcribe.</p>"
      }
    },
    "AudioEvent": {
      "base": "<p>Provides a wrapper for the audio chunks that you are sending.</p>",
      "refs": {
        "AudioStream$AudioEvent": "<p>A blob of audio from your application. You audio stream consists of one or more audio events.</p>"
      }
    },
    "AudioStream": {
      "base": "<p>Represents the audio stream from your application to Amazon Transcribe.</p>",
      "refs": {
        "StartStreamTranscriptionRequest$AudioStream": "<p>PCM-encoded stream of audio blobs. The audio stream is encoded as an HTTP2 data frame.</p>"
      }
    },
    "BadRequestException": {
      "base": "<p>One or more arguments to the <code>StartStreamTranscription</code> operation was invalid. For example, <code>MediaEncoding</code> was not set to <code>pcm</code> or <code>LanguageCode</code> was not set to a valid code. Check the parameters and try your request again.</p>",
      "refs": {
        "TranscriptResultStream$BadRequestException": "<p>A client error occurred when the stream was created. Check the parameters of the request and try your request again.</p>"
      }
    },
    "Boolean": {
      "base": null,
      "refs": {
        "Item$VocabularyFilterMatch": "<p>Indicates whether a word in the item matches a word in the vocabulary filter you've chosen for your real-time stream. If <code>true</code> then a word in the item matches your vocabulary filter.</p>",
        "Result$IsPartial": "<p>Amazon Transcribe divides the incoming audio stream into segments at natural points in the audio. Transcription results are returned based on these segments. </p> <p>The <code>IsPartial</code> field is <code>true</code> to indicate that Amazon Transcribe has additional transcription data to send, <code>false</code> to indicate that this is the last transcription result for the segment.</p>",
        "StartStreamTranscriptionRequest$ShowSpeakerLabel": "<p>When <code>true</code>, enables speaker identification in your real-time stream.</p>",
        "StartStreamTranscriptionRequest$EnableChannelIdentification": "<p>When <code>true</code>, instructs Amazon Transcribe to process each audio channel separately and then merge the transcription output of each channel into a single transcription.</p> <p>Amazon Transcribe also produces a transcription of each item. An item includes the start time, end time, and any alternative transcriptions.</p> <p>You can't set both <code>ShowSpeakerLabel</code> and <code>EnableChannelIdentification</code> in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>",
        "StartStreamTranscriptionResponse$ShowSpeakerLabel": "<p>Shows whether speaker identification was enabled in the stream.</p>",
        "StartStreamTranscriptionResponse$EnableChannelIdentification": "<p>Shows whether channel identification has been enabled in the stream.</p>"
      }
    },
    "ConflictException": {
      "base": "<p>A new stream started with the same session ID. The current stream has been terminated.</p>",
      "refs": {
        "TranscriptResultStream$ConflictException": "<p>A new stream started with the same session ID. The current stream has been terminated.</p>"
      }
    },
    "Double": {
      "base": null,
      "refs": {
        "Item$StartTime": "<p>The offset from the beginning of the audio stream to the beginning of the audio that resulted in the item.</p>",
        "Item$EndTime": "<p>The offset from the beginning of the audio stream to the end of the audio that resulted in the item.</p>",
        "Result$StartTime": "<p>The offset in seconds from the beginning of the audio stream to the beginning of the result.</p>",
        "Result$EndTime": "<p>The offset in seconds from the beginning of the audio stream to the end of the result.</p>"
      }
    },
    "InternalFailureException": {
      "base": "<p>A problem occurred while processing the audio. Amazon Transcribe terminated processing. Try your request again.</p>",
      "refs": {
        "TranscriptResultStream$InternalFailureException": "<p>A problem occurred while processing the audio. Amazon Transcribe terminated processing.</p>"
      }
    },
    "Item": {
      "base": "<p>A word or phrase transcribed from the input audio.</p>",
      "refs": {
        "ItemList$member": null
      }
    },
    "ItemList": {
      "base": null,
      "refs": {
        "Alternative$Items": "<p>One or more alternative interpretations of the input audio. </p>"
      }
    },
    "ItemType": {
      "base": null,
      "refs": {
        "Item$Type": "<p>The type of the item. <code>PRONUNCIATION</code> indicates that the item is a word that was recognized in the input audio. <code>PUNCTUATION</code> indicates that the item was interpreted as a pause in the input audio.</p>"
      }
    },
    "LanguageCode": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$LanguageCode": "<p>Indicates the source language used in the input audio stream.</p>",
        "StartStreamTranscriptionResponse$LanguageCode": "<p>The language code for the input audio stream.</p>"
      }
    },
    "LimitExceededException": {
      "base": "<p>You have exceeded the maximum number of concurrent transcription streams, are starting transcription streams too quickly, or the maximum audio length of 4 hours. Wait until a stream has finished processing, or break your audio stream into smaller chunks and try your request again.</p>",
      "refs": {
        "TranscriptResultStream$LimitExceededException": "<p>Your client has exceeded one of the Amazon Transcribe limits, typically the limit on audio length. Break your audio stream into smaller chunks and try your request again.</p>"
      }
    },
    "MediaEncoding": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$MediaEncoding": "<p>The encoding used for the input audio. <code>pcm</code> is the only valid value.</p>",
        "StartStreamTranscriptionResponse$MediaEncoding": "<p>The encoding used for the input audio stream.</p>"
      }
    },
    "MediaSampleRateHertz": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$MediaSampleRateHertz": "<p>The sample rate, in Hertz, of the input audio. We suggest that you use 8000 Hz for low quality audio and 16000 Hz for high quality audio.</p>",
        "StartStreamTranscriptionResponse$MediaSampleRateHertz": "<p>The sample rate for the input audio stream. Use 8000 Hz for low quality audio and 16000 Hz for high quality audio.</p>"
      }
    },
    "NumberOfChannels": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$NumberOfChannels": "<p>The number of channels that are in your audio stream.</p>",
        "StartStreamTranscriptionResponse$NumberOfChannels": "<p>The number of channels identified in the stream.</p>"
      }
    },
    "RequestId": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionResponse$RequestId": "<p>An identifier for the streaming transcription.</p>"
      }
    },
    "Result": {
      "base": "<p>The result of transcribing a portion of the input audio stream. </p>",
      "refs": {
        "ResultList$member": null
      }
    },
    "ResultList": {
      "base": null,
      "refs": {
        "Transcript$Results": "<p> <a>Result</a> objects that contain the results of transcribing a portion of the input audio stream. The array can be empty.</p>"
      }
    },
    "ServiceUnavailableException": {
      "base": "<p>Service is currently unavailable. Try your request later.</p>",
      "refs": {
        "TranscriptResultStream$ServiceUnavailableException": "<p>Service is currently unavailable. Try your request later.</p>"
      }
    },
    "SessionId": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$SessionId": "<p>A identifier for the transcription session. Use this parameter when you want to retry a session. If you don't provide a session ID, Amazon Transcribe will generate one for you and return it in the response.</p>",
        "StartStreamTranscriptionResponse$SessionId": "<p>An identifier for a specific transcription session.</p>"
      }
    },
    "StartStreamTranscriptionRequest": {
      "base": null,
      "refs": {
      }
    },
    "StartStreamTranscriptionResponse": {
      "base": null,
      "refs": {
      }
    },
    "String": {
      "base": null,
      "refs": {
        "Alternative$Transcript": "<p>The text that was transcribed from the audio.</p>",
        "BadRequestException$Message": null,
        "ConflictException$Message": null,
        "InternalFailureException$Message": null,
        "Item$Content": "<p>The word or punctuation that was recognized in the input audio.</p>",
        "Item$Speaker": "<p>If speaker identification is enabled, shows the speakers identified in the real-time stream.</p>",
        "LimitExceededException$Message": null,
        "Result$ResultId": "<p>A unique identifier for the result. </p>",
        "Result$ChannelId": "<p>When channel identification is enabled, Amazon Transcribe transcribes the speech from each audio channel separately.</p> <p>You can use <code>ChannelId</code> to retrieve the transcription results for a single channel in your audio stream.</p>",
        "ServiceUnavailableException$Message": null
      }
    },
    "Transcript": {
      "base": "<p>The transcription in a <a>TranscriptEvent</a>.</p>",
      "refs": {
        "TranscriptEvent$Transcript": "<p>The transcription of the audio stream. The transcription is composed of all of the items in the results list.</p>"
      }
    },
    "TranscriptEvent": {
      "base": "<p>Represents a set of transcription results from the server to the client. It contains one or more segments of the transcription.</p>",
      "refs": {
        "TranscriptResultStream$TranscriptEvent": "<p>A portion of the transcription of the audio stream. Events are sent periodically from Amazon Transcribe to your application. The event can be a partial transcription of a section of the audio stream, or it can be the entire transcription of that portion of the audio stream. </p>"
      }
    },
    "TranscriptResultStream": {
      "base": "<p>Represents the transcription result stream from Amazon Transcribe to your application.</p>",
      "refs": {
        "StartStreamTranscriptionResponse$TranscriptResultStream": "<p>Represents the stream of transcription events from Amazon Transcribe to your application.</p>"
      }
    },
    "VocabularyFilterMethod": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$VocabularyFilterMethod": "<p>The manner in which you use your vocabulary filter to filter words in your transcript. <code>Remove</code> removes filtered words from your transcription results. <code>Mask</code> masks those words with a <code>***</code> in your transcription results. <code>Tag</code> keeps the filtered words in your transcription results and tags them. The tag appears as <code>VocabularyFilterMatch</code> equal to <code>True</code> </p>",
        "StartStreamTranscriptionResponse$VocabularyFilterMethod": "<p>The vocabulary filtering method used in the real-time stream.</p>"
      }
    },
    "VocabularyFilterName": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$VocabularyFilterName": "<p>The name of the vocabulary filter you've created that is unique to your AWS account. Provide the name in this field to successfully use it in a stream.</p>",
        "StartStreamTranscriptionResponse$VocabularyFilterName": "<p>The name of the vocabulary filter used in your real-time stream.</p>"
      }
    },
    "VocabularyName": {
      "base": null,
      "refs": {
        "StartStreamTranscriptionRequest$VocabularyName": "<p>The name of the vocabulary to use when processing the transcription job.</p>",
        "StartStreamTranscriptionResponse$VocabularyName": "<p>The name of the vocabulary used when processing the stream.</p>"
      }
    }
  }
}
